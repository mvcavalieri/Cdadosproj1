{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome:Laura Perim\n",
    "\n",
    "Nome: Maria Victoria Cavalieri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\Vivi\\Documents\\Insper\\2semestre\\C dados\\Cdadosproj1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets= pd.read_excel('guarana.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "Guaran√° √© um refrigerante popular no Brasil. Consideramos relevantes os tweets que faziam refer√™ncia a qualidade do produto, tweets que diziam que o consumidor gosta/quer o produto, compara√ß√µes com outros refrigerantes ou caracter√≠sticas marcantes do produto, como manter o consumidor acordado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tomei c√°psula de guaran√°, caf√© e agora comprei...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eu e bruno 2 viciados em guaran√°</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>informa√ß√µes in√∫teis sobre mim:\\n\\naltura - n√£o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comendo aquela tapioca com guaran√° do amazonas...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@urryoonert guaran√° aqui n√£o √© refrigerante, t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  classificacao\n",
       "0  tomei c√°psula de guaran√°, caf√© e agora comprei...              2\n",
       "1                   eu e bruno 2 viciados em guaran√°              1\n",
       "2  informa√ß√µes in√∫teis sobre mim:\\n\\naltura - n√£o...              1\n",
       "3  comendo aquela tapioca com guaran√° do amazonas...              2\n",
       "4  @urryoonert guaran√° aqui n√£o √© refrigerante, t...              1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Treinamento classificacao\n",
      "0    tomei c√°psula de guaran√°, caf√© e agora comprei...   Irrelevante\n",
      "1                     eu e bruno 2 viciados em guaran√°     Relevante\n",
      "2    informa√ß√µes in√∫teis sobre mim:\\n\\naltura - n√£o...     Relevante\n",
      "3    comendo aquela tapioca com guaran√° do amazonas...   Irrelevante\n",
      "4    @urryoonert guaran√° aqui n√£o √© refrigerante, t...     Relevante\n",
      "5    comi um cachorro quente t√£o bom agr pqp queria...   Irrelevante\n",
      "6    @soulthatblooms guaran√° em p√≥ me lembra de um ...   Irrelevante\n",
      "7    tempo que eu n√£o sei oq √© festa cm bolo e guar...     Relevante\n",
      "8    @marcosquezado1 opa! program√£o, ein?! vou acom...     Relevante\n",
      "9    queria muito um estrogonofe de camar√£o e um gu...     Relevante\n",
      "10   rt @lacristina__: so trocar por coca ou guaran√° üëç     Relevante\n",
      "11   pensou em sabor ? #grquentinhas √© qualidade e ...   Irrelevante\n",
      "12   strogonoff com batata palha e guaran√° tudo pra...     Relevante\n",
      "13            vou tomar um copo de guaran√° e vou dormi     Relevante\n",
      "14   rt @vitoriafelix__: quem √© q come doce com gua...   Irrelevante\n",
      "15   caralho! como eu queria saber o contexto disso...   Irrelevante\n",
      "16   @nighttele nao falei amore, pra evitar conflit...   Irrelevante\n",
      "17   @francofrito mds... tu √© a segunda pessoa que ...   Irrelevante\n",
      "18   coisas que combinam:\\n\\npizza + guaran√°\\npipoc...     Relevante\n",
      "19   aqui em casa poder ter guarana n eu bebo toda ...     Relevante\n",
      "20   eu to com desejo de tomar dolly guaran√° pode i...     Relevante\n",
      "21   @hazukiyoumi dog na chapa esta√ßao ac 8 reais +...     Relevante\n",
      "22   comprei um refrizinho p toma com minha janta q...   Irrelevante\n",
      "23         alguem me da um guarana geladinho pod favir     Relevante\n",
      "24   a mina aqui no trampo t√° comendo um salgado e ...   Irrelevante\n",
      "25   renan perguntou se eu peguei guaran√° falei que...   Irrelevante\n",
      "26                    suco de guaran√° √© tudo de bom ne     Relevante\n",
      "27   @jenipatzlaff mano sim kkkkk parece guaran√° qu...   Irrelevante\n",
      "28   rt @werleeylima: a vida √© loka msm h√° uns anos...   Irrelevante\n",
      "29   p√≥ de guaran√° e amendoim, hoje eu t√¥ afim de c...     Relevante\n",
      "..                                                 ...           ...\n",
      "319                      precisava de um guaran√° agora     Relevante\n",
      "320  @garciasales @vittorguidoni me lembra um pouco...   Irrelevante\n",
      "321  pegar esse \"bolinho e guaran√°\" da vivian seman...   Irrelevante\n",
      "322  @starbockys hoje \\nvai ser \\numa festa\\nbolo e...   Irrelevante\n",
      "323  eu: filho quer suco?\\nele: n√£o m√£e, \"anuna\". (...   Irrelevante\n",
      "324  tava tomando guaran√° e n√£o tava matando a minh...   Irrelevante\n",
      "325  @linharesjnr @redemassa siiim.... as vezes usa...   Irrelevante\n",
      "326  tomo guarana, suco de caju, goiabada para sobr...   Irrelevante\n",
      "327  @guarana para de apoiar rodeio pra eu poder te...   Irrelevante\n",
      "328  pensou em sabor ? #grquentinhas √© qualidade e ...   Irrelevante\n",
      "329  @vola_volare vou fazer guaran√° com jabuticaba....   Irrelevante\n",
      "330  aquele p√≥s almo√ßo acompanhado de guaran√°, gelo...   Irrelevante\n",
      "331  rt @ferjhon33: ‚Äút√° bebendo guaran√° e t√° pegand...   Irrelevante\n",
      "332  @icaroanalises toddy\\nguaran√°\\nmarvel\\nde bruy...   Irrelevante\n",
      "333  @emanoel_bitt eu odeio qnd ei leio guar√°na\\nlo...   Irrelevante\n",
      "334  @_p4zz s√≥ um eno guaran√° depois kkk https://t....   Irrelevante\n",
      "335             @loveygmin n√£o tem, s√≥ guaran√° mesmo üòû   Irrelevante\n",
      "336  rt @jao4444: as crian√ßa na the choice embrasan...   Irrelevante\n",
      "337  rt @vitoriafelix__: quem √© q come doce com gua...   Irrelevante\n",
      "338  a belle pediu p mo√ßa da padaria guarda o guara...   Irrelevante\n",
      "339            @guarana os dois tem a mesma quantidade   Irrelevante\n",
      "340  guardei um gole do guarana que eu comprei pra ...   Irrelevante\n",
      "341                   @_fefob e meu caf√© e meu guaran√°     Relevante\n",
      "342  td q eu queria agora era um hamb√∫rguer da bk e...     Relevante\n",
      "343  olha s√≥ peguei minha folga na quinta pelo gren...   Irrelevante\n",
      "344  @claeruh parece o billy de st, √© escroto e faz...   Irrelevante\n",
      "345  tava com vinte conto e tava s√≥ a felicidade, f...     Relevante\n",
      "346  botei meu guaran√° no freezer e quase esque√ßo d...   Irrelevante\n",
      "347  e a vitoria que comeu bisnaga cm doritos enqnt...   Irrelevante\n",
      "348  [09/03/2020 23:36:47] kai: strogonoff\\n [09/03...   Irrelevante\n",
      "\n",
      "[349 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tomei c√°psula de guaran√°  caf√© e agora comprei outra parada pra dar energia  o cansa√ßo meu pai   '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.loc[:,'classificacao'] = tweets['classificacao'].astype('category') \n",
    "tweets.classificacao.cat.categories = ['Relevante', 'Irrelevante']\n",
    "print(tweets)\n",
    "import re \n",
    "def limpeza(dados):\n",
    "    import string\n",
    "    punctuation = '[!-.:?;,`¬¥]' \n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', dados)\n",
    "    return text_subbed\n",
    "limpeza(tweets['Treinamento'][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ler o texto de apenas os tweets classificados como relevantes\n",
    "relevante_col=tweets[tweets['classificacao']=='Relevante']['Treinamento'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevante_txt= \" \".join(relevante_col) # arrumando para forma de texto com espacos entre as palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eu e bruno 2 viciados em guaran√° informa√ß√µes in√∫teis sobre mim \\n\\naltura   n√£o sei\\ntamanho do p√©   37\\ntatuagens   0\\npiercing   0\\ncor fav   azul/preto/roxo\\nfilme fav   no momento capit√£o fant√°stico\\ns√©rie fav   stranger things\\ncomida fav   strogonoff/pizza\\nbebida fav   guaran√° https //t co/kqcleotkxg @urryoonert guaran√° aqui n√£o √© refrigerante  t√° mais para um refresco com muuuuuito a√ß√∫car kkk tempo que eu n√£o sei oq √© festa cm bolo e guaran√°  vagabundo s√≥ quer sabe de brahma e voodk cm energ√©tico ainda surgi a ousadia fudeu @marcosquezado1 opa  program√£o  ein   vou acompanhar com pipoca e guaran√°  mas esses militontos tem mudado de placa e cores    mesmo q extintos  o eleitor tem que aprender a escolher  e a apura√ß√£o dos votos tem que ser id√¥nea  queria muito um estrogonofe de camar√£o e um guaran√° ant√°rtica bem gelado   deus prfvr tenha piedade de mim rt @lacristina__  so trocar por coca ou guaran√° üëç strogonoff com batata palha e guaran√° tudo pra mim vou tomar um copo de guaran√° e vou dormi coisas que combinam \\n\\npizza   guaran√°\\npipoca   refrigerante\\nhamb√∫rguer   batata frita\\neu   voc√™ comendo tudo isso bb\\n\\nvai perder essa oportunidade  aqui em casa poder ter guarana n eu bebo toda hora mais agua q e bom nadaaaa eu to com desejo de tomar dolly guaran√° pode isso     @hazukiyoumi dog na chapa esta√ßao ac 8 reais   guarana em lata te amo alguem me da um guarana geladinho pod favir suco de guaran√° √© tudo de bom ne p√≥ de guaran√° e amendoim  hoje eu t√¥ afim de caprichar fui tomar p√≥ de guaran√° achando que tinha gosto de tang  quando fui ver era s√≥ a terra bom dia pessoal  hoje eu substitui uma x√≠cara de caf√© por uma colher de p√≥ de guaran√°  \\n\\n10 minutos atr√°s eu tava morrendo com uma pequena acelera√ß√£o  \\n\\n1¬∫ dia de p√≥ de guaran√° e zero sonos  \\nacompanhem o di√°rio rt @sulcideluk  charrua melhor guaran√° quem discorda t√° errado rt @brvmxs  10  40 da manha  acordar  tomar um caf√© da manh√£ saud√°vel com um guaran√° e depois jogar uma aramzinha c meu amor  ahaaaaam aquele guaran√° em p√≥ pra levantar a moral s√≥ bolinha de queijo  guaran√° e chocolate pra me fazer feliz hj    l√° vou eu gastar dinheiro na facul eu queria meu guaran√° jesus e o esa√∫ n guardou nada pra mim\\neu fiquei muito triste https //t co/1iwjfs581i @btsfeel hoje vai ser uma festa\\nbola e guaran√° muito doce pra comer\\n\\nfeliz anivers√°rio anjinho   \\nhttps //t co/mg4kmkotxs matei minha vontade de comer estrogonofe com copao de guaran√° ant√°rtica @favoriteany √© feito de guaran√° mas n√£o √© refrigerante  t√° mais para um refresco com muuuuuito a√ß√∫car charrua melhor guaran√° quem discorda t√° errado que guarana ruim √© esse kuat gosto de rem√©dio purinho  ainda me sobra varios dele    üò£ü§Æ a segunda feira j√° foi quase todo volume de trabalho concentrado num dia s√≥  hoje eu j√° acordei tomando meu shot de lim√£o adicionado de guaran√° em p√≥ e catei a c√°psula mais forte de caf√© que j√° passou por essa casa  agora s√≥ falta um guindaste me levantar porque t√° foda    guarana friburgo esta no meu top 3 de refrigerantes tudo que eu queria era aquele guaran√° do amazonas que vende no bonarabe @jasrwgers itiiiiiiiiijehehehejejeje oh meu deus a irm√£ te ama demais  traz bolo sim  vamos comer muito bolo e guaran√° parei de tomar refri h√° mais de um ano  pq eu quis  e o sabor que eu mais sinto falta √© o guaran√°  mas agora lan√ßaram o natu e eu preciso experimentar rt @rubinhoffc  guaran√° kuat n√£o √© refrigerante  √© rem√©dio queria tomar uns 2 litros de guaran√° jesus agr tlgd n sei se eu to adaptado ou se meu corpo ta mais resistente  to tomando caf√© e logo em seguido to bebendo guaran√° pra da energia e n adianta em porra nenhuma  @littlesacra tr√°s guaran√° jesus pa n√≥s amanh√£ vou gastar todo meu dinheiro com drogas  das mais pesadas  sem d√≥ nem piedade  bolo de chocolate  guaran√° da amaz√¥nia  milkshake  sunday vo ficar lokona @piiece_of_peace @agustdvv a√ßa√≠ de banana e guarana eu gosto  mas me enjoa r√°pido pq fica mt doce pra mim\\neu gosto de morango ou maracuja que a√≠ eu posso encher de complementos e n√£o enjoa nunca ‚ô• @hastadlol ja bebeu seu guarana hj  @mltbysungg @melhortutorial bebi umas 4 lata de guarana seguida  to e m b r e a g a d o eu te amo  guaran√° antarctica ontem n fui dormir mt bem e hoje tb n acordei legal    09h da manh√£ eu comendo bolinho de queijo e mistinho cheio de ketchup c um guaran√° bem geladinho  agora m sinto preparada p qualquer tombo da vida minha chefe manda eu ir assistir treinamento  s√≥ pra comer pipoca e tomar guaran√° üòÇüòÇüòÇ melhor n√£o tem ‚ù§Ô∏è rt @portellazzz  como que eu vou parar de tomar refri se guaran√° ant√°rtica √© a melhor coisa j√° criada nesse mundo   tentando estudar sem usar nada pra ficar acordada  mas estou falhando miseravelmente e vamos de energ√©tico e p√≥ de guaran√°  existem pessoas que amam guaran√° eu por exemplo tenho uma tatuagem disso   tatuagem do guaran√°  serio   n√£o √≥bvio que n√£o  eu lembrando que tenho a tatuagem do vinho @carlosfreitaaas quero o guaran√° t√° certo que eu prefiro guaran√° mas eu to bebendo uma coca bem geladinha ü§© sedenta por um copo de guaran√° o acreano q mora fora quando encontra qualquer projeto de a√ßa√≠ que nao tenha gosto de xarope de guaran√° nao quer guerra com ninguem acordei estressado  mas fui no mercado e lancei aquele guaran√° do bom vontade de comer um italiano quentinho e tomar um refrigerante de guaran√° caraca mane  que desejo absurdo que eu to de tomar um guaran√° ant√°rtica geladin @hastadlol os cara curte guaran√° rt @melbruu  se tem uma coisa que eu gosto de beber √© guaran√° natural pqp ü§§ü§§ü§§ to viciada em guaran√° mix e agora mds      rt @giibatistaa  td q eu queria agora era um hamb√∫rguer da bk e aquele refil de guaran√° ant√°rctica mais um ga√∫cho conhecendo o melhor guaran√° que existe üíÅüèº\\u200d‚ôÄÔ∏èüòÖ https //t co/rqrecjptcq eu pago um suquinho de guaran√° queria tomar um guaran√° da heineken n√£o resisto a um guaran√° ant√°rtica üòãü§¶ quase 5h da manh√£ e eu c vontade de tomar guaran√° ü§¶üèª\\u200d‚ôÄÔ∏è kkkkkkkkkkkk se tem uma coisa que eu gosto de beber √© guaran√° natural pqp ü§§ü§§ü§§ @rick_c99 guaran√° e melhor tava ha umas semanas sem beber nenhum refri e fui inventar de beber hoje um guaran√°  vei n√£o aguentei dar 2 goles que sensa√ß√£o horr√≠vel o que eu n√£o daria por um empad√£o e um guaran√° agora a pessoa q come um hamb√∫rguer c cheddar e um guaran√° ant√°rctica no caf√© da manh√£ n quer guerra c ngm a grande rio vem de guaran√° mesmo  https //t co/w6cefsjjnf lembrei de um sorvete de guarana q eu comi anteontem nodsa foi a pior coisa q eu ja tomei na minha vida juro thiago comprou um mont√£o de coisa no domingo  j√° acabou tudo  at√© o guaran√° kkkkkkkkkkkkkkkkkkk q √≥dio s√≥ queria saber onde eu encontro o guaran√° ant√°rtica 100  natural sou a mulher mais feliz comendo yakissoba e tomando guarana jesus @2xminilyce aa guaran√° n√£o √© mt bom  mas caso vc n√£o tiver melhor amanh√£  se ai onde vc mora tiver ch√° de boldo ajuda mt guaran√° ant√°rctica   √≥bvio @guarana este √© o melhor guaran√° do mundo amoü•∞ü•∞ü•∞ e se eu comesse um hamburgao com guarana agora https //t co/pev1lu3902 rt @potterlov3  queria muito um estrogonofe de camar√£o e um guaran√° ant√°rtica bem gelado   deus prfvr tenha piedade de mim a cada 30 min pego um pouco de guaran√° jesus q era p fim de semana veja o novo refrigerante da guaran√° antarctica sem a√ß√∫car e corantes https //t co/y7sujfowch https //t co/3duhazc4yr rt @emilly_uai  √© logico que guaran√°  √© melhor  que coca plmd @gabrielolivf me chama eu levo guarana e po a √∫nica vontade √© enrolar as duas pizza da nono picoli e comer tomando o guaran√° q vem na promo guarana zero de visual novo      estranhei    mas ta lindinha de roupa nova  https //t co/ltlaoxzmyw deus  meu deus  pq eu como 10 coxinhas com guaran√° e dps reclamo q to gorda  guaran√° antarctica  √© melhor que coca cola  queria tomar um suco de guaran√° @joosepulveda2 grapette e guaran√° coroa juntos √© pedir pra morrer @lovesurreax kjkjjkkkk eh guaran√° com mais a√ß√∫car e melhor acho que n√£o existe ngm mais apaixonada do que eu por conven√ß√£o guaran√° üòãüòç‚ù§Ô∏è crlh ryan fominha de guaran√° eu sei q todo mundo acha mas ningu√©m tem coragem pra falar     suco de guaran√° √© bom pakas a √∫ltima vez que eu tomei caf√© e po de guaran√° eu n√£o parava quieta  vamos ver n√© meu cunhado fez um neg√≥cio de a√ßa√≠ com p√≥ de guaran√° e estou aqui ligadona e sem sono @rafarosadas eu sou suco de manga/uva e refri sem gas de guaran√°  nao fico sem amg\\nn√£o consigo gostar de agua com gas n vejo sentindoooooo ‚Äútia me d√° guaran√°‚Äù ü•∞ü•∞ü•∞ vontade de um guaran√° geladinho puta merda √∫nico refrigerante que me d√° gatilho √© o guaran√° garoto q eu n√£o posso ver q meu cerebro fica o pr√≥prio meme\\n\\nquelo beber refrigelante tomei uma xicara de caf√© puto de forte e um cp de guaran√° extra e to lutando com meus olhos p fica aberto üò• pepsi  coca cola e guaran√° ant√°rtica s√£o os melhores refris da vida queria almo√ßar uma saladinha da esta√ß√£o do guaran√° ‚òπÔ∏è rt @candeiakethlyn  guaran√° √© mt melhor q coca @mavivalenza guaran√° em p√≥  √© bom  mas se vc trm problema no cora√ß√£o talvez seja um pouco arriscado melhores bebidas do brasil  guaravita e guaran√° jesus e sem choro https //t co/cspq5zyrvs @lukasssid meti 3 burgao com 3 guaran√° por 13 50 to feliz demais fi td q eu queria agora era um hamb√∫rguer da bk e aquele refil de guaran√° ant√°rctica @babs_costa t√¥ tomando guaran√° a uma semana  n√£o fez efeito algum  tem que tomar a cafe√≠na em c√°psulas mesmo se gabi levar guaran√° jesus pra mim eu vou ser a mulher mais feliz de plan√≠cie rt @hrmnyj  guaran√° antartica √© mil vezes melhor q coca  sou do rj e vim dizer que o camp de uva √© o melhor guarana https //t co/gmcy2z4atg precisava de um guaran√° agora pedi ela pra  comprar suco de a√ßai com guaran√° e ela me vem com laranja com mam√£o a m√©dica  nada de guaran√° em mariana \\neu as 5 00 da manh√£  quelo gualana gelado tomei uma c√°psula de guaran√°  espero que me ajude pq to quase falecendo real n√£o aguento mais tomar guaran√° ü§Æ fantaü§Æ kkkkkkkkkkkk ele √© demais  desse tamanho viciado guaran√° https //t co/vkp6j2sath eu tentando suprir minha vontade de comer a√ß√∫car tomando guaran√° zero \\n\\nodioooo caralho eu amo guaran√° cruzeiro q vontade louca de tomar um refri  um guaran√° bem geladinho ü•∫ü§¶\\u200d‚ôÄÔ∏è quem inventou o guaran√° kuat devia t√° c mt √≥dio da popula√ß√£o pqp q bag horr√≠vel @radcurtain meu deus amo esse guaran√° tomei c√°psula de guaran√°  caf√© e agora comprei outra parada pra dar energia  o cansa√ßo meu pai    precisava de um guaran√° agora @_fefob e meu caf√© e meu guaran√° td q eu queria agora era um hamb√∫rguer da bk e aquele refil de guaran√° ant√°rctica tava com vinte conto e tava s√≥ a felicidade  fui pra outra cidade e bati um prato de estrogonofe com uma guaran√° de 1l me arrependi e quero meu dinheiro de volta  o estrogonofe tava top mas eu t√¥ pobre üò≠üò≠üò≠ '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#limpando o texto com a funcao\n",
    "relevante_txt_limpo = limpeza(relevante_txt)\n",
    "relevante_txt_limpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guaran√°             0.058885\n",
      "de                  0.047942\n",
      "e                   0.035435\n",
      "eu                  0.028140\n",
      "um                  0.022408\n",
      "que                 0.017718\n",
      "√©                   0.013549\n",
      "a                   0.013028\n",
      "o                   0.011985\n",
      "com                 0.011464\n",
      "q                   0.010422\n",
      "n√£o                 0.010422\n",
      "da                  0.009901\n",
      "tomar               0.008338\n",
      "meu                 0.007817\n",
      "pra                 0.007817\n",
      "guarana             0.007295\n",
      "mais                0.007295\n",
      "uma                 0.007295\n",
      "melhor              0.007295\n",
      "to                  0.006253\n",
      "agora               0.006253\n",
      "//t                 0.006253\n",
      "mas                 0.006253\n",
      "https               0.006253\n",
      "queria              0.006253\n",
      "em                  0.005732\n",
      "rt                  0.005732\n",
      "me                  0.005732\n",
      "do                  0.005211\n",
      "                      ...   \n",
      "40                  0.000521\n",
      "guindaste           0.000521\n",
      "militontos          0.000521\n",
      "pessoa              0.000521\n",
      "arriscado           0.000521\n",
      "uva                 0.000521\n",
      "@emilly_uai         0.000521\n",
      "d                   0.000521\n",
      "4                   0.000521\n",
      "c√°psulas            0.000521\n",
      "h√°                  0.000521\n",
      "refrigelante        0.000521\n",
      "@btsfeel            0.000521\n",
      "chapa               0.000521\n",
      "problema            0.000521\n",
      "ama                 0.000521\n",
      "37                  0.000521\n",
      "gualana             0.000521\n",
      "esta√ß√£o             0.000521\n",
      "frita               0.000521\n",
      "brahma              0.000521\n",
      "sabe                0.000521\n",
      "cada                0.000521\n",
      "tombo               0.000521\n",
      "viciados            0.000521\n",
      "strogonoff/pizza    0.000521\n",
      "domingo             0.000521\n",
      "neg√≥cio             0.000521\n",
      "@mltbysungg         0.000521\n",
      "vim                 0.000521\n",
      "Length: 740, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#arrumando todas as palavras relevantes para  calcular a  frequencia relativa delas\n",
    "todas_rel= relevante_txt_limpo.split()\n",
    "serie_rel = pd.Series(todas_rel) \n",
    "tabela_relativar= serie_rel.value_counts(True)\n",
    "print(tabela_relativar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ler o texto de apenas os tweets classificados como irrelevantes\n",
    "\n",
    "irrelevante_col=tweets[tweets['classificacao']=='Irrelevante']['Treinamento']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrumando para forma de texto com espacos entre as palavras\n",
    "irrelevante_txt= \" \".join(irrelevante_col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevante_txt_limpo = limpeza(irrelevante_txt) #limpando o texto com a funcao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guaran√°            0.041597\n",
      "e                  0.029166\n",
      "de                 0.028688\n",
      "eu                 0.020798\n",
      "√©                  0.018647\n",
      "que                0.017213\n",
      "a                  0.016256\n",
      "o                  0.015300\n",
      "com                0.012670\n",
      "um                 0.012670\n",
      "do                 0.010519\n",
      "em                 0.009323\n",
      "//t                0.009084\n",
      "pra                0.009084\n",
      "https              0.009084\n",
      "uma                0.007889\n",
      "n√£o                0.007172\n",
      "rt                 0.006455\n",
      "da                 0.005977\n",
      "q                  0.005977\n",
      "meu                0.005738\n",
      "na                 0.005498\n",
      "l√°                 0.005259\n",
      "se                 0.005020\n",
      "mas                0.004781\n",
      "ou                 0.004542\n",
      "no                 0.004303\n",
      "voc√™               0.004303\n",
      "me                 0.004064\n",
      "s√≥                 0.004064\n",
      "                     ...   \n",
      "v√¥                 0.000239\n",
      "@sakatasanx        0.000239\n",
      "vidro              0.000239\n",
      "coloquei           0.000239\n",
      "matando            0.000239\n",
      "achei              0.000239\n",
      "tanto              0.000239\n",
      "paraense           0.000239\n",
      "cacha√ßa            0.000239\n",
      "51                 0.000239\n",
      "frango             0.000239\n",
      "@_gbarth           0.000239\n",
      "üéµdollyüé∂            0.000239\n",
      "amorzinho          0.000239\n",
      "enfim              0.000239\n",
      "@alanadelrei       0.000239\n",
      "ret√≥rico           0.000239\n",
      "almo√ßar            0.000239\n",
      "burra              0.000239\n",
      "segredou           0.000239\n",
      "mourinho           0.000239\n",
      "seis               0.000239\n",
      "pagar              0.000239\n",
      "praia              0.000239\n",
      "boninho            0.000239\n",
      "pequeno            0.000239\n",
      "@pqsumiram         0.000239\n",
      "tosse              0.000239\n",
      "üòÇüòÇüòÇüòÇüòÇüòÇ             0.000239\n",
      "industrializado    0.000239\n",
      "Length: 1353, dtype: float64\n",
      "guaran√°             0.058885\n",
      "de                  0.047942\n",
      "e                   0.035435\n",
      "eu                  0.028140\n",
      "um                  0.022408\n",
      "que                 0.017718\n",
      "√©                   0.013549\n",
      "a                   0.013028\n",
      "o                   0.011985\n",
      "com                 0.011464\n",
      "q                   0.010422\n",
      "n√£o                 0.010422\n",
      "da                  0.009901\n",
      "tomar               0.008338\n",
      "meu                 0.007817\n",
      "pra                 0.007817\n",
      "guarana             0.007295\n",
      "mais                0.007295\n",
      "uma                 0.007295\n",
      "melhor              0.007295\n",
      "to                  0.006253\n",
      "agora               0.006253\n",
      "//t                 0.006253\n",
      "mas                 0.006253\n",
      "https               0.006253\n",
      "queria              0.006253\n",
      "em                  0.005732\n",
      "rt                  0.005732\n",
      "me                  0.005732\n",
      "do                  0.005211\n",
      "                      ...   \n",
      "40                  0.000521\n",
      "guindaste           0.000521\n",
      "militontos          0.000521\n",
      "pessoa              0.000521\n",
      "arriscado           0.000521\n",
      "uva                 0.000521\n",
      "@emilly_uai         0.000521\n",
      "d                   0.000521\n",
      "4                   0.000521\n",
      "c√°psulas            0.000521\n",
      "h√°                  0.000521\n",
      "refrigelante        0.000521\n",
      "@btsfeel            0.000521\n",
      "chapa               0.000521\n",
      "problema            0.000521\n",
      "ama                 0.000521\n",
      "37                  0.000521\n",
      "gualana             0.000521\n",
      "esta√ß√£o             0.000521\n",
      "frita               0.000521\n",
      "brahma              0.000521\n",
      "sabe                0.000521\n",
      "cada                0.000521\n",
      "tombo               0.000521\n",
      "viciados            0.000521\n",
      "strogonoff/pizza    0.000521\n",
      "domingo             0.000521\n",
      "neg√≥cio             0.000521\n",
      "@mltbysungg         0.000521\n",
      "vim                 0.000521\n",
      "Length: 740, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#irrelevante_contagem = pd.DataFrame(irrelevante_txt_limpo.split())\n",
    "todas_irrel=  irrelevante_txt_limpo.split()\n",
    "serie_irrel= pd.Series(todas_irrel)\n",
    "tabela_relativai= serie_irrel.value_counts(True)\n",
    "print(tabela_relativai)\n",
    "print(tabela_relativar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guaran√°           0.047034\n",
      "de                0.034743\n",
      "e                 0.031137\n",
      "eu                0.023107\n",
      "que               0.017371\n",
      "√©                 0.017044\n",
      "um                0.015733\n",
      "a                 0.015241\n",
      "o                 0.014258\n",
      "com               0.012291\n",
      "do                0.008850\n",
      "pra               0.008686\n",
      "https             0.008194\n",
      "//t               0.008194\n",
      "em                0.008194\n",
      "n√£o               0.008194\n",
      "uma               0.007702\n",
      "q                 0.007375\n",
      "da                0.007211\n",
      "meu               0.006391\n",
      "rt                0.006227\n",
      "mas               0.005244\n",
      "se                0.004916\n",
      "guarana           0.004916\n",
      "mais              0.004589\n",
      "me                0.004589\n",
      "na                0.004425\n",
      "no                0.004097\n",
      "s√≥                0.004097\n",
      "l√°                0.003769\n",
      "                    ...   \n",
      "fodasse           0.000164\n",
      "co/tngsmifbpa     0.000164\n",
      "@astronamaia      0.000164\n",
      "abriram           0.000164\n",
      "@hrmnyj           0.000164\n",
      "co/vuy36clqcl     0.000164\n",
      "louca             0.000164\n",
      "vitoria           0.000164\n",
      "@4uexpbr          0.000164\n",
      "000               0.000164\n",
      "facada            0.000164\n",
      "ketchup           0.000164\n",
      "amooor            0.000164\n",
      "estressado        0.000164\n",
      "v√°rios            0.000164\n",
      "surgi             0.000164\n",
      "falecendo         0.000164\n",
      "cunhado           0.000164\n",
      "prontamente       0.000164\n",
      "rancho            0.000164\n",
      "pela              0.000164\n",
      "‚Ä¢                 0.000164\n",
      "dando             0.000164\n",
      "preparando        0.000164\n",
      "nossa             0.000164\n",
      "consegue          0.000164\n",
      "esfomeada         0.000164\n",
      "@caixeta_edmar    0.000164\n",
      "goles             0.000164\n",
      "entrar            0.000164\n",
      "Length: 1771, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#frequencia relativa das palavras relevantes e irrelevantes juntas\n",
    "todas_palavras= relevante_txt_limpo + irrelevante_txt_limpo\n",
    "serie_tudo= pd.Series(todas_palavras.split())\n",
    "tabela_relativa_tudo= serie_tudo.value_counts(True)\n",
    "print(tabela_relativa_tudo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             tomei\n",
      "1           c√°psula\n",
      "2                de\n",
      "3           guaran√°\n",
      "4              caf√©\n",
      "5                 e\n",
      "6             agora\n",
      "7           comprei\n",
      "8             outra\n",
      "9            parada\n",
      "10              pra\n",
      "11              dar\n",
      "12          energia\n",
      "13                o\n",
      "14          cansa√ßo\n",
      "15              meu\n",
      "16              pai\n",
      "17          comendo\n",
      "18           aquela\n",
      "19          tapioca\n",
      "20              com\n",
      "21          guaran√°\n",
      "22               do\n",
      "23         amazonas\n",
      "24              pra\n",
      "25              dar\n",
      "26                a\n",
      "27            for√ßa\n",
      "28                p\n",
      "29          encarar\n",
      "           ...     \n",
      "4153        guarana\n",
      "4154    [09/03/2020\n",
      "4155             23\n",
      "4156             36\n",
      "4157            47]\n",
      "4158            kai\n",
      "4159     strogonoff\n",
      "4160    [09/03/2020\n",
      "4161             23\n",
      "4162             36\n",
      "4163            49]\n",
      "4164            kai\n",
      "4165            com\n",
      "4166           coca\n",
      "4167    [09/03/2020\n",
      "4168             23\n",
      "4169             36\n",
      "4170            56]\n",
      "4171         irm√£oüíï\n",
      "4172              n\n",
      "4173           bebo\n",
      "4174        guaran√°\n",
      "4175    [09/03/2020\n",
      "4176             23\n",
      "4177             37\n",
      "4178            03]\n",
      "4179            kai\n",
      "4180            mas\n",
      "4181             eu\n",
      "4182           bebo\n",
      "Length: 4183, dtype: object\n",
      "0                    eu\n",
      "1                     e\n",
      "2                 bruno\n",
      "3                     2\n",
      "4              viciados\n",
      "5                    em\n",
      "6               guaran√°\n",
      "7           informa√ß√µes\n",
      "8               in√∫teis\n",
      "9                 sobre\n",
      "10                  mim\n",
      "11               altura\n",
      "12                  n√£o\n",
      "13                  sei\n",
      "14              tamanho\n",
      "15                   do\n",
      "16                   p√©\n",
      "17                   37\n",
      "18            tatuagens\n",
      "19                    0\n",
      "20             piercing\n",
      "21                    0\n",
      "22                  cor\n",
      "23                  fav\n",
      "24      azul/preto/roxo\n",
      "25                filme\n",
      "26                  fav\n",
      "27                   no\n",
      "28              momento\n",
      "29              capit√£o\n",
      "             ...       \n",
      "1889              outra\n",
      "1890             cidade\n",
      "1891                  e\n",
      "1892               bati\n",
      "1893                 um\n",
      "1894              prato\n",
      "1895                 de\n",
      "1896        estrogonofe\n",
      "1897                com\n",
      "1898                uma\n",
      "1899            guaran√°\n",
      "1900                 de\n",
      "1901                 1l\n",
      "1902                 me\n",
      "1903          arrependi\n",
      "1904                  e\n",
      "1905              quero\n",
      "1906                meu\n",
      "1907           dinheiro\n",
      "1908                 de\n",
      "1909              volta\n",
      "1910                  o\n",
      "1911        estrogonofe\n",
      "1912               tava\n",
      "1913                top\n",
      "1914                mas\n",
      "1915                 eu\n",
      "1916                 t√¥\n",
      "1917              pobre\n",
      "1918                üò≠üò≠üò≠\n",
      "Length: 1919, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(serie_irrel) #numero total de palavras irrelevantes √© 4177\n",
    "print(serie_rel) #n√∫mero total de palavras relevantes √© 1919"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6855129465748935\n",
      "0.3144870534251065\n"
     ]
    }
   ],
   "source": [
    "probI= len(serie_irrel)/len(serie_tudo)\n",
    "probR= len(serie_rel)/len(serie_tudo)\n",
    "print(probI)\n",
    "print(probR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guaran√°            174\n",
      "e                  122\n",
      "de                 120\n",
      "eu                  87\n",
      "√©                   78\n",
      "que                 72\n",
      "a                   68\n",
      "o                   64\n",
      "com                 53\n",
      "um                  53\n",
      "do                  44\n",
      "em                  39\n",
      "//t                 38\n",
      "pra                 38\n",
      "https               38\n",
      "uma                 33\n",
      "n√£o                 30\n",
      "rt                  27\n",
      "da                  25\n",
      "q                   25\n",
      "meu                 24\n",
      "na                  23\n",
      "l√°                  22\n",
      "se                  21\n",
      "mas                 20\n",
      "ou                  19\n",
      "no                  18\n",
      "voc√™                18\n",
      "me                  17\n",
      "s√≥                  17\n",
      "                  ... \n",
      "v√¥                   1\n",
      "@sakatasanx          1\n",
      "vidro                1\n",
      "coloquei             1\n",
      "matando              1\n",
      "achei                1\n",
      "tanto                1\n",
      "paraense             1\n",
      "cacha√ßa              1\n",
      "51                   1\n",
      "frango               1\n",
      "@_gbarth             1\n",
      "üéµdollyüé∂              1\n",
      "amorzinho            1\n",
      "enfim                1\n",
      "@alanadelrei         1\n",
      "ret√≥rico             1\n",
      "almo√ßar              1\n",
      "burra                1\n",
      "segredou             1\n",
      "mourinho             1\n",
      "seis                 1\n",
      "pagar                1\n",
      "praia                1\n",
      "boninho              1\n",
      "pequeno              1\n",
      "@pqsumiram           1\n",
      "tosse                1\n",
      "üòÇüòÇüòÇüòÇüòÇüòÇ               1\n",
      "industrializado      1\n",
      "Length: 1353, dtype: int64\n",
      "guaran√°             113\n",
      "de                   92\n",
      "e                    68\n",
      "eu                   54\n",
      "um                   43\n",
      "que                  34\n",
      "√©                    26\n",
      "a                    25\n",
      "o                    23\n",
      "com                  22\n",
      "q                    20\n",
      "n√£o                  20\n",
      "da                   19\n",
      "tomar                16\n",
      "meu                  15\n",
      "pra                  15\n",
      "guarana              14\n",
      "mais                 14\n",
      "uma                  14\n",
      "melhor               14\n",
      "to                   12\n",
      "agora                12\n",
      "//t                  12\n",
      "mas                  12\n",
      "https                12\n",
      "queria               12\n",
      "em                   11\n",
      "rt                   11\n",
      "me                   11\n",
      "do                   10\n",
      "                   ... \n",
      "40                    1\n",
      "guindaste             1\n",
      "militontos            1\n",
      "pessoa                1\n",
      "arriscado             1\n",
      "uva                   1\n",
      "@emilly_uai           1\n",
      "d                     1\n",
      "4                     1\n",
      "c√°psulas              1\n",
      "h√°                    1\n",
      "refrigelante          1\n",
      "@btsfeel              1\n",
      "chapa                 1\n",
      "problema              1\n",
      "ama                   1\n",
      "37                    1\n",
      "gualana               1\n",
      "esta√ß√£o               1\n",
      "frita                 1\n",
      "brahma                1\n",
      "sabe                  1\n",
      "cada                  1\n",
      "tombo                 1\n",
      "viciados              1\n",
      "strogonoff/pizza      1\n",
      "domingo               1\n",
      "neg√≥cio               1\n",
      "@mltbysungg           1\n",
      "vim                   1\n",
      "Length: 740, dtype: int64\n",
      "0                    eu\n",
      "1                     e\n",
      "2                 bruno\n",
      "3                     2\n",
      "4              viciados\n",
      "5                    em\n",
      "6               guaran√°\n",
      "7           informa√ß√µes\n",
      "8               in√∫teis\n",
      "9                 sobre\n",
      "10                  mim\n",
      "11               altura\n",
      "12                  n√£o\n",
      "13                  sei\n",
      "14              tamanho\n",
      "15                   do\n",
      "16                   p√©\n",
      "17                   37\n",
      "18            tatuagens\n",
      "19                    0\n",
      "20             piercing\n",
      "21                    0\n",
      "22                  cor\n",
      "23                  fav\n",
      "24      azul/preto/roxo\n",
      "25                filme\n",
      "26                  fav\n",
      "27                   no\n",
      "28              momento\n",
      "29              capit√£o\n",
      "             ...       \n",
      "1889              outra\n",
      "1890             cidade\n",
      "1891                  e\n",
      "1892               bati\n",
      "1893                 um\n",
      "1894              prato\n",
      "1895                 de\n",
      "1896        estrogonofe\n",
      "1897                com\n",
      "1898                uma\n",
      "1899            guaran√°\n",
      "1900                 de\n",
      "1901                 1l\n",
      "1902                 me\n",
      "1903          arrependi\n",
      "1904                  e\n",
      "1905              quero\n",
      "1906                meu\n",
      "1907           dinheiro\n",
      "1908                 de\n",
      "1909              volta\n",
      "1910                  o\n",
      "1911        estrogonofe\n",
      "1912               tava\n",
      "1913                top\n",
      "1914                mas\n",
      "1915                 eu\n",
      "1916                 t√¥\n",
      "1917              pobre\n",
      "1918                üò≠üò≠üò≠\n",
      "Length: 1919, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#quantas vezes aparecem cada palavra\n",
    "freq_irrel= serie_irrel.value_counts()\n",
    "print(freq_irrel)\n",
    "freq_rel= serie_rel.value_counts()\n",
    "print(freq_rel)\n",
    "print(serie_rel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1354\n",
      "740\n"
     ]
    }
   ],
   "source": [
    "somaI= 1354 #length da tabela frequ√™ncias relativas irrelevantes\n",
    "somaR= 740\n",
    "print(somaI)\n",
    "print(somaR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tweetsteste= pd.read_excel('guarana.xlsx',sheet_name='Teste')  # Puxa o dataset\n",
    "tweetsteste[\"Teste s/ pont.\"] = tweetsteste[\"Teste\"].apply(limpeza) # Aplica \"Limpeza\" automaticamente\n",
    "\n",
    "tw_teste = tweetsteste[\"Teste s/ pont.\"] # Seleciona apenas a coluna de tweets ap√≥s a limpeza\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_teste = [] \n",
    "for i in tw_teste:                \n",
    "    tweets_teste.append(i.split())\n",
    "# Forloop faz com que a lista \"tweets_teste\" vire uma lista de listas\n",
    "# Cada indice de \"tweets_teste\" √© um tweet (separado por palavra) em formato de lista\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_relevancia=[]\n",
    "lista_irrelevancia=[]\n",
    "classificacao=[]\n",
    "d=1772 #n√∫mero total de palavras diferentes em ambas as s√©ries\n",
    "\n",
    "\n",
    "for tweet in tweets_teste:\n",
    "    i=0\n",
    "    alfa= 1\n",
    "    probTweetI= 1\n",
    "    probTweetR=1\n",
    "#     print(palavras)\n",
    "    for palavra in tweet:\n",
    "    #calculando a prob do tweet ser irrelevante\n",
    "#         print('Esta √© PI')\n",
    "#         print(probTweetR)\n",
    "        if palavra in freq_irrel:\n",
    "            probTweetI*= (freq_irrel[palavra] +alfa)/(d +somaI)\n",
    "#             print('if 1')\n",
    "#             print(freq_irrel[palavra])\n",
    "#             print(probTweetI)\n",
    "        if palavra not in freq_irrel:\n",
    "            probTweetI*=1/(d+ somaI)\n",
    "            (probTweetI)\n",
    "        if palavra in freq_rel:\n",
    "            probTweetR*= (freq_rel[palavra]+alfa)/(d+ somaR)\n",
    "        if palavra not in freq_rel:\n",
    "            probTweetR*=1/(d+ somaR)\n",
    "    lista_irrelevancia.append(probI*probTweetI)\n",
    "    lista_relevancia.append(probR*probTweetR)\n",
    "\n",
    "    \n",
    "for i in range(0,149):\n",
    "    if lista_relevancia[i]<lista_irrelevancia[i]:\n",
    "        classificacao.append(2)\n",
    "    else:\n",
    "        classificacao.append(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "alpha= np.arange(0,1,0.01)\n",
    "for z in alpha:\n",
    "    acertos=0\n",
    "    for i in range(0,149):     \n",
    "        if lista_relevancia[i]>(z*(lista_irrelevancia[i]+lista_relevancia[i])):\n",
    "            classif=1      \n",
    "        else:\n",
    "            classif=2\n",
    "        if tweetsteste['classificacao'][i]==classif:\n",
    "            acertos+=1\n",
    "        \n",
    "        \n",
    "    \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>classificacao</th>\n",
       "      <th>irrelevancia</th>\n",
       "      <th>relevante</th>\n",
       "      <th>classificacao_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@waagfreeitas kkkkk guaran√° do jovem</td>\n",
       "      <td>2</td>\n",
       "      <td>1.085107e-13</td>\n",
       "      <td>3.942776e-15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@joaomiguelbdb bicho eu penso isso mas com rel...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.786614e-48</td>\n",
       "      <td>4.270914e-49</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a belle pediu p mo√ßa da padaria guarda o guara...</td>\n",
       "      <td>2</td>\n",
       "      <td>2.176839e-50</td>\n",
       "      <td>3.233497e-56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ï°∞ÏäπÏó∞ posta foto que eu te dou churrasco e guarana</td>\n",
       "      <td>2</td>\n",
       "      <td>2.790289e-27</td>\n",
       "      <td>2.505172e-28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@calebesouzao @pedrotolhos @guarana por nada, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.037496e-40</td>\n",
       "      <td>7.803109e-43</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  classificacao  \\\n",
       "0               @waagfreeitas kkkkk guaran√° do jovem              2   \n",
       "1  @joaomiguelbdb bicho eu penso isso mas com rel...              2   \n",
       "2  a belle pediu p mo√ßa da padaria guarda o guara...              2   \n",
       "3   Ï°∞ÏäπÏó∞ posta foto que eu te dou churrasco e guarana              2   \n",
       "4  @calebesouzao @pedrotolhos @guarana por nada, ...              2   \n",
       "\n",
       "   irrelevancia     relevante  classificacao_comp  \n",
       "0  1.085107e-13  3.942776e-15                   2  \n",
       "1  3.786614e-48  4.270914e-49                   2  \n",
       "2  2.176839e-50  3.233497e-56                   2  \n",
       "3  2.790289e-27  2.505172e-28                   2  \n",
       "4  1.037496e-40  7.803109e-43                   2  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tweetsteste= pd.read_excel('guarana.xlsx',sheet_name='Teste')\n",
    "df = pd.DataFrame(tweetsteste)\n",
    "tweets_teste= tweetsteste['Teste']\n",
    "\n",
    "tweetsteste[\"irrelevancia\"]= lista_irrelevancia\n",
    "tweetsteste[\"relevante\"]= lista_relevancia\n",
    "tweetsteste[\"classificacao_comp\"]= classificacao\n",
    "\n",
    "tweetsteste.head()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>classificacao_comp</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classificacao</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.104762</td>\n",
       "      <td>0.895238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "classificacao_comp         1         2\n",
       "classificacao                         \n",
       "1                   0.386364  0.613636\n",
       "2                   0.104762  0.895238"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsteste.head(100)\n",
    "pd.crosstab(tweetsteste['classificacao'],tweetsteste['classificacao_comp'],normalize='index')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando classificar Relevante como positivo:\n",
    "Falsos Positivos= 10,4%\n",
    "Falsos Negativos= 61,3%\n",
    "Positivos Verdadeiros= 38,6%\n",
    "Falsos Verdadeiros= 89%\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos concluir que nosso classificador tem uma precis√£o muito boa para classificar Tweets como Irrelevantes, mas ainda precisa de mais tweets Relevantes em seu banco de dados para aumentar sua precis√£o na classifica√ß√£o de Tweets Relevantes, uma vez que uma diversidade maior de palavras ter√≠am suas frequ√™ncias aumentando a precis√£o das classifica√ß√µeos. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprimorando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para aprimorar nosso Classificador, poder√≠amos tamb√©m adicionar melhorias na fun√ß√£o de limpeza, retirando, por exemplo o s√≠mbolo 'https://\", com a fun√ß√£o replace. Tamb√©m poder√≠amos criar classifica√ß√µes intermedi√°rias as propostas, como Muito Relevante e Neutro, o que exigiria um espa√ßo amostral maior de tweets, outro ponto que seria uma melhoria para nosso classificador. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outras aplica√ß√µes para o classificador\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Detectar spams em e-mails ( palavras frequentes em spams seriam detectadas e e-mails com muitas daquelas palavras seriam descartados)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Classificador de texto, ou seja, identifica√ß√£o de qual assunto se trata aquele texto, que pode ser √∫til para categoriz√°-los de forma autom√°tica para uma biblioteca virtual, por exemplo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-√Årea da medicina, probabilidade de um indiv√≠duo ter alguma doen√ßa e an√°lise da efic√°cia de exames, com as chances do teste ser falso positivo ou negativo, positivo verdadeiro etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porqu√™ n√£o posso usar o classificador para gerar mais amostras de treinamento?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O classificador n√£o pode ser utilizado para gerar mais amostras treinamento porque o classificador que montamos j√° possui um \"vi√©s\", ou seja, as palavras \"in√©ditas\" que o classificador verificaria j√° teriam sido pr√©viamente analisadas por ele, ent√£o os mesmos erros seriam cometidos e o estudo confluiria sempre para uma mesma conclus√£o ( que ele j√° teria previamente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
