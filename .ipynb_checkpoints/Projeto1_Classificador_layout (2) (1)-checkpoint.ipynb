{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome:Laura Perim\n",
    "\n",
    "Nome: Maria Victoria Cavalieri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\laura\\Documents\\2 semestre\\Cdadosproj1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets= pd.read_excel('guarana.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "Guaran√° √© um refrigerante popular no Brasil. Consideramos relevantes os tweets que faziam refer√™ncia a qualidade do produto, tweets que diziam que o consumidor gosta/quer o produto, compara√ß√µes com outros refrigerantes ou caracter√≠sticas marcantes do produto, como manter o consumidor acordado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>classificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tomei c√°psula de guaran√°, caf√© e agora comprei...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eu e bruno 2 viciados em guaran√°</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>informa√ß√µes in√∫teis sobre mim:\\n\\naltura - n√£o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comendo aquela tapioca com guaran√° do amazonas...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@urryoonert guaran√° aqui n√£o √© refrigerante, t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  classificacao\n",
       "0  tomei c√°psula de guaran√°, caf√© e agora comprei...              2\n",
       "1                   eu e bruno 2 viciados em guaran√°              1\n",
       "2  informa√ß√µes in√∫teis sobre mim:\\n\\naltura - n√£o...              1\n",
       "3  comendo aquela tapioca com guaran√° do amazonas...              2\n",
       "4  @urryoonert guaran√° aqui n√£o √© refrigerante, t...              1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Treinamento classificacao\n",
      "0    tomei c√°psula de guaran√°, caf√© e agora comprei...   Irrelevante\n",
      "1                     eu e bruno 2 viciados em guaran√°     Relevante\n",
      "2    informa√ß√µes in√∫teis sobre mim:\\n\\naltura - n√£o...     Relevante\n",
      "3    comendo aquela tapioca com guaran√° do amazonas...   Irrelevante\n",
      "4    @urryoonert guaran√° aqui n√£o √© refrigerante, t...     Relevante\n",
      "5    comi um cachorro quente t√£o bom agr pqp queria...   Irrelevante\n",
      "6    @soulthatblooms guaran√° em p√≥ me lembra de um ...   Irrelevante\n",
      "7    tempo que eu n√£o sei oq √© festa cm bolo e guar...     Relevante\n",
      "8    @marcosquezado1 opa! program√£o, ein?! vou acom...     Relevante\n",
      "9    queria muito um estrogonofe de camar√£o e um gu...     Relevante\n",
      "10   rt @lacristina__: so trocar por coca ou guaran√° üëç     Relevante\n",
      "11   pensou em sabor ? #grquentinhas √© qualidade e ...   Irrelevante\n",
      "12   strogonoff com batata palha e guaran√° tudo pra...     Relevante\n",
      "13            vou tomar um copo de guaran√° e vou dormi     Relevante\n",
      "14   rt @vitoriafelix__: quem √© q come doce com gua...   Irrelevante\n",
      "15   caralho! como eu queria saber o contexto disso...   Irrelevante\n",
      "16   @nighttele nao falei amore, pra evitar conflit...   Irrelevante\n",
      "17   @francofrito mds... tu √© a segunda pessoa que ...   Irrelevante\n",
      "18   coisas que combinam:\\n\\npizza + guaran√°\\npipoc...     Relevante\n",
      "19   aqui em casa poder ter guarana n eu bebo toda ...     Relevante\n",
      "20   eu to com desejo de tomar dolly guaran√° pode i...     Relevante\n",
      "21   @hazukiyoumi dog na chapa esta√ßao ac 8 reais +...     Relevante\n",
      "22   comprei um refrizinho p toma com minha janta q...   Irrelevante\n",
      "23         alguem me da um guarana geladinho pod favir     Relevante\n",
      "24   a mina aqui no trampo t√° comendo um salgado e ...   Irrelevante\n",
      "25   renan perguntou se eu peguei guaran√° falei que...   Irrelevante\n",
      "26                    suco de guaran√° √© tudo de bom ne     Relevante\n",
      "27   @jenipatzlaff mano sim kkkkk parece guaran√° qu...   Irrelevante\n",
      "28   rt @werleeylima: a vida √© loka msm h√° uns anos...   Irrelevante\n",
      "29   p√≥ de guaran√° e amendoim, hoje eu t√¥ afim de c...     Relevante\n",
      "..                                                 ...           ...\n",
      "319                      precisava de um guaran√° agora     Relevante\n",
      "320  @garciasales @vittorguidoni me lembra um pouco...   Irrelevante\n",
      "321  pegar esse \"bolinho e guaran√°\" da vivian seman...   Irrelevante\n",
      "322  @starbockys hoje \\nvai ser \\numa festa\\nbolo e...   Irrelevante\n",
      "323  eu: filho quer suco?\\nele: n√£o m√£e, \"anuna\". (...   Irrelevante\n",
      "324  tava tomando guaran√° e n√£o tava matando a minh...   Irrelevante\n",
      "325  @linharesjnr @redemassa siiim.... as vezes usa...   Irrelevante\n",
      "326  tomo guarana, suco de caju, goiabada para sobr...   Irrelevante\n",
      "327  @guarana para de apoiar rodeio pra eu poder te...   Irrelevante\n",
      "328  pensou em sabor ? #grquentinhas √© qualidade e ...   Irrelevante\n",
      "329  @vola_volare vou fazer guaran√° com jabuticaba....   Irrelevante\n",
      "330  aquele p√≥s almo√ßo acompanhado de guaran√°, gelo...   Irrelevante\n",
      "331  rt @ferjhon33: ‚Äút√° bebendo guaran√° e t√° pegand...   Irrelevante\n",
      "332  @icaroanalises toddy\\nguaran√°\\nmarvel\\nde bruy...   Irrelevante\n",
      "333  @emanoel_bitt eu odeio qnd ei leio guar√°na\\nlo...   Irrelevante\n",
      "334  @_p4zz s√≥ um eno guaran√° depois kkk https://t....   Irrelevante\n",
      "335             @loveygmin n√£o tem, s√≥ guaran√° mesmo üòû   Irrelevante\n",
      "336  rt @jao4444: as crian√ßa na the choice embrasan...   Irrelevante\n",
      "337  rt @vitoriafelix__: quem √© q come doce com gua...   Irrelevante\n",
      "338  a belle pediu p mo√ßa da padaria guarda o guara...   Irrelevante\n",
      "339            @guarana os dois tem a mesma quantidade   Irrelevante\n",
      "340  guardei um gole do guarana que eu comprei pra ...   Irrelevante\n",
      "341                   @_fefob e meu caf√© e meu guaran√°     Relevante\n",
      "342  td q eu queria agora era um hamb√∫rguer da bk e...     Relevante\n",
      "343  olha s√≥ peguei minha folga na quinta pelo gren...   Irrelevante\n",
      "344  @claeruh parece o billy de st, √© escroto e faz...   Irrelevante\n",
      "345  tava com vinte conto e tava s√≥ a felicidade, f...     Relevante\n",
      "346  botei meu guaran√° no freezer e quase esque√ßo d...   Irrelevante\n",
      "347  e a vitoria que comeu bisnaga cm doritos enqnt...   Irrelevante\n",
      "348  [09/03/2020 23:36:47] kai: strogonoff\\n [09/03...   Irrelevante\n",
      "\n",
      "[349 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tomei c√°psula de guaran√°  caf√© e agora comprei outra parada pra dar energia  o cansa√ßo meu pai   '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.loc[:,'classificacao'] = tweets['classificacao'].astype('category') \n",
    "tweets.classificacao.cat.categories = ['Relevante', 'Irrelevante']\n",
    "print(tweets)\n",
    "import re \n",
    "def limpeza(dados):\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;,]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', dados)\n",
    "    return text_subbed\n",
    "limpeza(tweets['Treinamento'][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ler o texto de apenas os tweets classificados como relevantes\n",
    "relevante_col=tweets[tweets['classificacao']=='Relevante']['Treinamento'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevante_txt= \" \".join(relevante_col) # arrumando para forma de texto com espacos entre as palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eu e bruno 2 viciados em guaran√° informa√ß√µes in√∫teis sobre mim \\n\\naltura   n√£o sei\\ntamanho do p√©   37\\ntatuagens   0\\npiercing   0\\ncor fav   azul/preto/roxo\\nfilme fav   no momento capit√£o fant√°stico\\ns√©rie fav   stranger things\\ncomida fav   strogonoff/pizza\\nbebida fav   guaran√° https //t co/kqcleotkxg @urryoonert guaran√° aqui n√£o √© refrigerante  t√° mais para um refresco com muuuuuito a√ß√∫car kkk tempo que eu n√£o sei oq √© festa cm bolo e guaran√°  vagabundo s√≥ quer sabe de brahma e voodk cm energ√©tico ainda surgi a ousadia fudeu @marcosquezado1 opa  program√£o  ein   vou acompanhar com pipoca e guaran√°  mas esses militontos tem mudado de placa e cores    mesmo q extintos  o eleitor tem que aprender a escolher  e a apura√ß√£o dos votos tem que ser id√¥nea  queria muito um estrogonofe de camar√£o e um guaran√° ant√°rtica bem gelado   deus prfvr tenha piedade de mim rt @lacristina__  so trocar por coca ou guaran√° üëç strogonoff com batata palha e guaran√° tudo pra mim vou tomar um copo de guaran√° e vou dormi coisas que combinam \\n\\npizza   guaran√°\\npipoca   refrigerante\\nhamb√∫rguer   batata frita\\neu   voc√™ comendo tudo isso bb\\n\\nvai perder essa oportunidade  aqui em casa poder ter guarana n eu bebo toda hora mais agua q e bom nadaaaa eu to com desejo de tomar dolly guaran√° pode isso     @hazukiyoumi dog na chapa esta√ßao ac 8 reais   guarana em lata te amo alguem me da um guarana geladinho pod favir suco de guaran√° √© tudo de bom ne p√≥ de guaran√° e amendoim  hoje eu t√¥ afim de caprichar fui tomar p√≥ de guaran√° achando que tinha gosto de tang  quando fui ver era s√≥ a terra bom dia pessoal  hoje eu substitui uma x√≠cara de caf√© por uma colher de p√≥ de guaran√°  \\n\\n10 minutos atr√°s eu tava morrendo com uma pequena acelera√ß√£o  \\n\\n1¬∫ dia de p√≥ de guaran√° e zero sonos  \\nacompanhem o di√°rio rt @sulcideluk  charrua melhor guaran√° quem discorda t√° errado rt @brvmxs  10  40 da manha  acordar  tomar um caf√© da manh√£ saud√°vel com um guaran√° e depois jogar uma aramzinha c meu amor  ahaaaaam aquele guaran√° em p√≥ pra levantar a moral s√≥ bolinha de queijo  guaran√° e chocolate pra me fazer feliz hj    l√° vou eu gastar dinheiro na facul eu queria meu guaran√° jesus e o esa√∫ n guardou nada pra mim\\neu fiquei muito triste https //t co/1iwjfs581i @btsfeel hoje vai ser uma festa\\nbola e guaran√° muito doce pra comer\\n\\nfeliz anivers√°rio anjinho   \\nhttps //t co/mg4kmkotxs matei minha vontade de comer estrogonofe com copao de guaran√° ant√°rtica @favoriteany √© feito de guaran√° mas n√£o √© refrigerante  t√° mais para um refresco com muuuuuito a√ß√∫car charrua melhor guaran√° quem discorda t√° errado que guarana ruim √© esse kuat gosto de rem√©dio purinho  ainda me sobra varios dele    üò£ü§Æ a segunda feira j√° foi quase todo volume de trabalho concentrado num dia s√≥  hoje eu j√° acordei tomando meu shot de lim√£o adicionado de guaran√° em p√≥ e catei a c√°psula mais forte de caf√© que j√° passou por essa casa  agora s√≥ falta um guindaste me levantar porque t√° foda    guarana friburgo esta no meu top 3 de refrigerantes tudo que eu queria era aquele guaran√° do amazonas que vende no bonarabe @jasrwgers itiiiiiiiiijehehehejejeje oh meu deus a irm√£ te ama demais  traz bolo sim  vamos comer muito bolo e guaran√° parei de tomar refri h√° mais de um ano  pq eu quis  e o sabor que eu mais sinto falta √© o guaran√°  mas agora lan√ßaram o natu e eu preciso experimentar rt @rubinhoffc  guaran√° kuat n√£o √© refrigerante  √© rem√©dio queria tomar uns 2 litros de guaran√° jesus agr tlgd n sei se eu to adaptado ou se meu corpo ta mais resistente  to tomando caf√© e logo em seguido to bebendo guaran√° pra da energia e n adianta em porra nenhuma  @littlesacra tr√°s guaran√° jesus pa n√≥s amanh√£ vou gastar todo meu dinheiro com drogas  das mais pesadas  sem d√≥ nem piedade  bolo de chocolate  guaran√° da amaz√¥nia  milkshake  sunday vo ficar lokona @piiece_of_peace @agustdvv a√ßa√≠ de banana e guarana eu gosto  mas me enjoa r√°pido pq fica mt doce pra mim\\neu gosto de morango ou maracuja que a√≠ eu posso encher de complementos e n√£o enjoa nunca ‚ô• @hastadlol ja bebeu seu guarana hj  @mltbysungg @melhortutorial bebi umas 4 lata de guarana seguida  to e m b r e a g a d o eu te amo  guaran√° antarctica ontem n fui dormir mt bem e hoje tb n acordei legal    09h da manh√£ eu comendo bolinho de queijo e mistinho cheio de ketchup c um guaran√° bem geladinho  agora m sinto preparada p qualquer tombo da vida minha chefe manda eu ir assistir treinamento  s√≥ pra comer pipoca e tomar guaran√° üòÇüòÇüòÇ melhor n√£o tem ‚ù§Ô∏è rt @portellazzz  como que eu vou parar de tomar refri se guaran√° ant√°rtica √© a melhor coisa j√° criada nesse mundo   tentando estudar sem usar nada pra ficar acordada  mas estou falhando miseravelmente e vamos de energ√©tico e p√≥ de guaran√°  existem pessoas que amam guaran√° eu por exemplo tenho uma tatuagem disso   tatuagem do guaran√°  serio   n√£o √≥bvio que n√£o  eu lembrando que tenho a tatuagem do vinho @carlosfreitaaas quero o guaran√° t√° certo que eu prefiro guaran√° mas eu to bebendo uma coca bem geladinha ü§© sedenta por um copo de guaran√° o acreano q mora fora quando encontra qualquer projeto de a√ßa√≠ que nao tenha gosto de xarope de guaran√° nao quer guerra com ninguem acordei estressado  mas fui no mercado e lancei aquele guaran√° do bom vontade de comer um italiano quentinho e tomar um refrigerante de guaran√° caraca mane  que desejo absurdo que eu to de tomar um guaran√° ant√°rtica geladin @hastadlol os cara curte guaran√° rt @melbruu  se tem uma coisa que eu gosto de beber √© guaran√° natural pqp ü§§ü§§ü§§ to viciada em guaran√° mix e agora mds      rt @giibatistaa  td q eu queria agora era um hamb√∫rguer da bk e aquele refil de guaran√° ant√°rctica mais um ga√∫cho conhecendo o melhor guaran√° que existe üíÅüèº\\u200d‚ôÄÔ∏èüòÖ https //t co/rqrecjptcq eu pago um suquinho de guaran√° queria tomar um guaran√° da heineken n√£o resisto a um guaran√° ant√°rtica üòãü§¶ quase 5h da manh√£ e eu c vontade de tomar guaran√° ü§¶üèª\\u200d‚ôÄÔ∏è kkkkkkkkkkkk se tem uma coisa que eu gosto de beber √© guaran√° natural pqp ü§§ü§§ü§§ @rick_c99 guaran√° e melhor tava ha umas semanas sem beber nenhum refri e fui inventar de beber hoje um guaran√°  vei n√£o aguentei dar 2 goles que sensa√ß√£o horr√≠vel o que eu n√£o daria por um empad√£o e um guaran√° agora a pessoa q come um hamb√∫rguer c cheddar e um guaran√° ant√°rctica no caf√© da manh√£ n quer guerra c ngm a grande rio vem de guaran√° mesmo  https //t co/w6cefsjjnf lembrei de um sorvete de guarana q eu comi anteontem nodsa foi a pior coisa q eu ja tomei na minha vida juro thiago comprou um mont√£o de coisa no domingo  j√° acabou tudo  at√© o guaran√° kkkkkkkkkkkkkkkkkkk q √≥dio s√≥ queria saber onde eu encontro o guaran√° ant√°rtica 100  natural sou a mulher mais feliz comendo yakissoba e tomando guarana jesus @2xminilyce aa guaran√° n√£o √© mt bom  mas caso vc n√£o tiver melhor amanh√£  se ai onde vc mora tiver ch√° de boldo ajuda mt guaran√° ant√°rctica   √≥bvio @guarana este √© o melhor guaran√° do mundo amoü•∞ü•∞ü•∞ e se eu comesse um hamburgao com guarana agora https //t co/pev1lu3902 rt @potterlov3  queria muito um estrogonofe de camar√£o e um guaran√° ant√°rtica bem gelado   deus prfvr tenha piedade de mim a cada 30 min pego um pouco de guaran√° jesus q era p fim de semana veja o novo refrigerante da guaran√° antarctica sem a√ß√∫car e corantes https //t co/y7sujfowch https //t co/3duhazc4yr rt @emilly_uai  √© logico que guaran√°  √© melhor  que coca plmd @gabrielolivf me chama eu levo guarana e po a √∫nica vontade √© enrolar as duas pizza da nono picoli e comer tomando o guaran√° q vem na promo guarana zero de visual novo      estranhei    mas ta lindinha de roupa nova  https //t co/ltlaoxzmyw deus  meu deus  pq eu como 10 coxinhas com guaran√° e dps reclamo q to gorda  guaran√° antarctica  √© melhor que coca cola  queria tomar um suco de guaran√° @joosepulveda2 grapette e guaran√° coroa juntos √© pedir pra morrer @lovesurreax kjkjjkkkk eh guaran√° com mais a√ß√∫car e melhor acho que n√£o existe ngm mais apaixonada do que eu por conven√ß√£o guaran√° üòãüòç‚ù§Ô∏è crlh ryan fominha de guaran√° eu sei q todo mundo acha mas ningu√©m tem coragem pra falar     suco de guaran√° √© bom pakas a √∫ltima vez que eu tomei caf√© e po de guaran√° eu n√£o parava quieta  vamos ver n√© meu cunhado fez um neg√≥cio de a√ßa√≠ com p√≥ de guaran√° e estou aqui ligadona e sem sono @rafarosadas eu sou suco de manga/uva e refri sem gas de guaran√°  nao fico sem amg\\nn√£o consigo gostar de agua com gas n vejo sentindoooooo ‚Äútia me d√° guaran√°‚Äù ü•∞ü•∞ü•∞ vontade de um guaran√° geladinho puta merda √∫nico refrigerante que me d√° gatilho √© o guaran√° garoto q eu n√£o posso ver q meu cerebro fica o pr√≥prio meme\\n\\nquelo beber refrigelante tomei uma xicara de caf√© puto de forte e um cp de guaran√° extra e to lutando com meus olhos p fica aberto üò• pepsi  coca cola e guaran√° ant√°rtica s√£o os melhores refris da vida queria almo√ßar uma saladinha da esta√ß√£o do guaran√° ‚òπÔ∏è rt @candeiakethlyn  guaran√° √© mt melhor q coca @mavivalenza guaran√° em p√≥  √© bom  mas se vc trm problema no cora√ß√£o talvez seja um pouco arriscado melhores bebidas do brasil  guaravita e guaran√° jesus e sem choro https //t co/cspq5zyrvs @lukasssid meti 3 burgao com 3 guaran√° por 13 50 to feliz demais fi td q eu queria agora era um hamb√∫rguer da bk e aquele refil de guaran√° ant√°rctica @babs_costa t√¥ tomando guaran√° a uma semana  n√£o fez efeito algum  tem que tomar a cafe√≠na em c√°psulas mesmo se gabi levar guaran√° jesus pra mim eu vou ser a mulher mais feliz de plan√≠cie rt @hrmnyj  guaran√° antartica √© mil vezes melhor q coca  sou do rj e vim dizer que o camp de uva √© o melhor guarana https //t co/gmcy2z4atg precisava de um guaran√° agora pedi ela pra  comprar suco de a√ßai com guaran√° e ela me vem com laranja com mam√£o a m√©dica  nada de guaran√° em mariana \\neu as 5 00 da manh√£  quelo gualana gelado tomei uma c√°psula de guaran√°  espero que me ajude pq to quase falecendo real n√£o aguento mais tomar guaran√° ü§Æ fantaü§Æ kkkkkkkkkkkk ele √© demais  desse tamanho viciado guaran√° https //t co/vkp6j2sath eu tentando suprir minha vontade de comer a√ß√∫car tomando guaran√° zero \\n\\nodioooo caralho eu amo guaran√° cruzeiro q vontade louca de tomar um refri  um guaran√° bem geladinho ü•∫ü§¶\\u200d‚ôÄÔ∏è quem inventou o guaran√° kuat devia t√° c mt √≥dio da popula√ß√£o pqp q bag horr√≠vel @radcurtain meu deus amo esse guaran√° tomei c√°psula de guaran√°  caf√© e agora comprei outra parada pra dar energia  o cansa√ßo meu pai    precisava de um guaran√° agora @_fefob e meu caf√© e meu guaran√° td q eu queria agora era um hamb√∫rguer da bk e aquele refil de guaran√° ant√°rctica tava com vinte conto e tava s√≥ a felicidade  fui pra outra cidade e bati um prato de estrogonofe com uma guaran√° de 1l me arrependi e quero meu dinheiro de volta  o estrogonofe tava top mas eu t√¥ pobre üò≠üò≠üò≠ '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#limpando o texto com a funcao\n",
    "relevante_txt_limpo = limpeza(relevante_txt)\n",
    "relevante_txt_limpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arrumando todas as palavras relevantes para  calcular a  frequencia relativa delas\n",
    "todas_rel= relevante_txt_limpo.split()\n",
    "serie_rel = pd.Series(todas_rel) \n",
    "tabela_relativar= serie_rel.value_counts(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ler o texto de apenas os tweets classificados como irrelevantes\n",
    "\n",
    "irrelevante_col=tweets[tweets['classificacao']=='Irrelevante']['Treinamento']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrumando para forma de texto com espacos entre as palavras\n",
    "irrelevante_txt= \" \".join(irrelevante_col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevante_txt_limpo = limpeza(irrelevante_txt) #limpando o texto com a funcao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guaran√°            0.041657\n",
      "e                  0.029208\n",
      "de                 0.028729\n",
      "eu                 0.020828\n",
      "√©                  0.018674\n",
      "que                0.017237\n",
      "a                  0.016280\n",
      "o                  0.015322\n",
      "com                0.012689\n",
      "um                 0.012689\n",
      "do                 0.010534\n",
      "em                 0.009337\n",
      "//t                0.009097\n",
      "https              0.009097\n",
      "pra                0.009097\n",
      "uma                0.007900\n",
      "n√£o                0.007182\n",
      "rt                 0.006464\n",
      "da                 0.005985\n",
      "q                  0.005985\n",
      "meu                0.005746\n",
      "na                 0.005506\n",
      "l√°                 0.005267\n",
      "se                 0.005028\n",
      "mas                0.004788\n",
      "ou                 0.004549\n",
      "no                 0.004309\n",
      "voc√™               0.004309\n",
      "j√°                 0.004070\n",
      "@guarana           0.004070\n",
      "                     ...   \n",
      "estar              0.000239\n",
      "caracu             0.000239\n",
      "ganha              0.000239\n",
      "forma              0.000239\n",
      "7x1                0.000239\n",
      "kapo               0.000239\n",
      "cozinha            0.000239\n",
      "nego               0.000239\n",
      "tentar             0.000239\n",
      "@pedrxcarvalho     0.000239\n",
      "@namgukoo          0.000239\n",
      "suja               0.000239\n",
      "vitoria            0.000239\n",
      "protege            0.000239\n",
      "estabelecimento    0.000239\n",
      "combinamos         0.000239\n",
      "vinho              0.000239\n",
      "moska              0.000239\n",
      "raiz               0.000239\n",
      "legal              0.000239\n",
      "tomado             0.000239\n",
      "50                 0.000239\n",
      "barraco            0.000239\n",
      "@agustdvv          0.000239\n",
      "ifood              0.000239\n",
      "eternet            0.000239\n",
      "trof√©u             0.000239\n",
      "porra              0.000239\n",
      "todos              0.000239\n",
      "parab√©ns           0.000239\n",
      "Length: 1354, dtype: float64\n",
      "guaran√°             0.058885\n",
      "de                  0.047942\n",
      "e                   0.035435\n",
      "eu                  0.028140\n",
      "um                  0.022408\n",
      "que                 0.017718\n",
      "√©                   0.013549\n",
      "a                   0.013028\n",
      "o                   0.011985\n",
      "com                 0.011464\n",
      "q                   0.010422\n",
      "n√£o                 0.010422\n",
      "da                  0.009901\n",
      "tomar               0.008338\n",
      "meu                 0.007817\n",
      "pra                 0.007817\n",
      "melhor              0.007295\n",
      "guarana             0.007295\n",
      "mais                0.007295\n",
      "uma                 0.007295\n",
      "agora               0.006253\n",
      "https               0.006253\n",
      "queria              0.006253\n",
      "to                  0.006253\n",
      "mas                 0.006253\n",
      "//t                 0.006253\n",
      "em                  0.005732\n",
      "rt                  0.005732\n",
      "me                  0.005732\n",
      "do                  0.005211\n",
      "                      ...   \n",
      "eh                  0.000521\n",
      "louca               0.000521\n",
      "pessoa              0.000521\n",
      "ü§©                   0.000521\n",
      "shot                0.000521\n",
      "piercing            0.000521\n",
      "@lukasssid          0.000521\n",
      "ano                 0.000521\n",
      "ningu√©m             0.000521\n",
      "rj                  0.000521\n",
      "absurdo             0.000521\n",
      "juntos              0.000521\n",
      "manda               0.000521\n",
      "goles               0.000521\n",
      "sabor               0.000521\n",
      "√∫nica               0.000521\n",
      "@brvmxs             0.000521\n",
      "concentrado         0.000521\n",
      "@emilly_uai         0.000521\n",
      "foda                0.000521\n",
      "comi                0.000521\n",
      "anivers√°rio         0.000521\n",
      "bag                 0.000521\n",
      "arriscado           0.000521\n",
      "aprender            0.000521\n",
      "@piiece_of_peace    0.000521\n",
      "dps                 0.000521\n",
      "ga√∫cho              0.000521\n",
      "seu                 0.000521\n",
      "so                  0.000521\n",
      "Length: 740, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#irrelevante_contagem = pd.DataFrame(irrelevante_txt_limpo.split())\n",
    "todas_irrel=  irrelevante_txt_limpo.split()\n",
    "serie_irrel= pd.Series(todas_irrel)\n",
    "tabela_relativai= serie_irrel.value_counts(True)\n",
    "print(tabela_relativai)\n",
    "print(tabela_relativar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guaran√°          0.047080\n",
      "de               0.034777\n",
      "e                0.031168\n",
      "eu               0.023130\n",
      "que              0.017388\n",
      "√©                0.017060\n",
      "um               0.015748\n",
      "a                0.015256\n",
      "o                0.014272\n",
      "com              0.012303\n",
      "do               0.008858\n",
      "pra              0.008694\n",
      "https            0.008202\n",
      "em               0.008202\n",
      "n√£o              0.008202\n",
      "//t              0.008202\n",
      "uma              0.007710\n",
      "q                0.007382\n",
      "da               0.007218\n",
      "meu              0.006398\n",
      "rt               0.006234\n",
      "mas              0.005249\n",
      "se               0.004921\n",
      "guarana          0.004921\n",
      "mais             0.004593\n",
      "me               0.004593\n",
      "na               0.004429\n",
      "s√≥               0.004101\n",
      "no               0.004101\n",
      "tomar            0.003773\n",
      "                   ...   \n",
      "14               0.000164\n",
      "todos            0.000164\n",
      "lobinho          0.000164\n",
      "falecendo        0.000164\n",
      "cerebro          0.000164\n",
      "lancei           0.000164\n",
      "friburgo         0.000164\n",
      "fil√©             0.000164\n",
      "mandei           0.000164\n",
      "trouxa           0.000164\n",
      "@rafarosadas     0.000164\n",
      "pequeno          0.000164\n",
      "dupla            0.000164\n",
      "brigar           0.000164\n",
      "chegar           0.000164\n",
      "ü•∞ü•∞ü•∞              0.000164\n",
      "trof√©u           0.000164\n",
      "reconhecida      0.000164\n",
      "troco            0.000164\n",
      "‚Ä¢¬¥¬Ø`\\            0.000164\n",
      "piscina          0.000164\n",
      "ifood            0.000164\n",
      "@yngrid_crf23    0.000164\n",
      "barraco          0.000164\n",
      "ano              0.000164\n",
      "@pqsumiram       0.000164\n",
      "joinha           0.000164\n",
      "comprou          0.000164\n",
      "doritos          0.000164\n",
      "burgao           0.000164\n",
      "Length: 1772, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#frequencia relativa das palavras relevantes e irrelevantes juntas\n",
    "todas_palavras= relevante_txt_limpo + irrelevante_txt_limpo\n",
    "serie_tudo= pd.Series(todas_palavras.split())\n",
    "tabela_relativa_tudo= serie_tudo.value_counts(True)\n",
    "print(tabela_relativa_tudo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6852034120734908\n",
      "0.31479658792650916\n"
     ]
    }
   ],
   "source": [
    "probI= len(serie_irrel)/len(serie_tudo)\n",
    "probR= len(serie_rel)/len(serie_tudo)\n",
    "print(probI)\n",
    "print(probR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                    eu\n",
      "1                     e\n",
      "2                 bruno\n",
      "3                     2\n",
      "4              viciados\n",
      "5                    em\n",
      "6               guaran√°\n",
      "7           informa√ß√µes\n",
      "8               in√∫teis\n",
      "9                 sobre\n",
      "10                  mim\n",
      "11               altura\n",
      "12                  n√£o\n",
      "13                  sei\n",
      "14              tamanho\n",
      "15                   do\n",
      "16                   p√©\n",
      "17                   37\n",
      "18            tatuagens\n",
      "19                    0\n",
      "20             piercing\n",
      "21                    0\n",
      "22                  cor\n",
      "23                  fav\n",
      "24      azul/preto/roxo\n",
      "25                filme\n",
      "26                  fav\n",
      "27                   no\n",
      "28              momento\n",
      "29              capit√£o\n",
      "             ...       \n",
      "6066            guarana\n",
      "6067        [09/03/2020\n",
      "6068                 23\n",
      "6069                 36\n",
      "6070                47]\n",
      "6071                kai\n",
      "6072         strogonoff\n",
      "6073        [09/03/2020\n",
      "6074                 23\n",
      "6075                 36\n",
      "6076                49]\n",
      "6077                kai\n",
      "6078                com\n",
      "6079               coca\n",
      "6080        [09/03/2020\n",
      "6081                 23\n",
      "6082                 36\n",
      "6083                56]\n",
      "6084             irm√£oüíï\n",
      "6085                  n\n",
      "6086               bebo\n",
      "6087            guaran√°\n",
      "6088        [09/03/2020\n",
      "6089                 23\n",
      "6090                 37\n",
      "6091                03]\n",
      "6092                kai\n",
      "6093                mas\n",
      "6094                 eu\n",
      "6095               bebo\n",
      "Length: 6096, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(serie_tudo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guaran√°            174\n",
      "e                  122\n",
      "de                 120\n",
      "eu                  87\n",
      "√©                   78\n",
      "que                 72\n",
      "a                   68\n",
      "o                   64\n",
      "com                 53\n",
      "um                  53\n",
      "do                  44\n",
      "em                  39\n",
      "//t                 38\n",
      "https               38\n",
      "pra                 38\n",
      "uma                 33\n",
      "n√£o                 30\n",
      "rt                  27\n",
      "da                  25\n",
      "q                   25\n",
      "meu                 24\n",
      "na                  23\n",
      "l√°                  22\n",
      "se                  21\n",
      "mas                 20\n",
      "ou                  19\n",
      "no                  18\n",
      "voc√™                18\n",
      "j√°                  17\n",
      "@guarana            17\n",
      "                  ... \n",
      "estar                1\n",
      "caracu               1\n",
      "ganha                1\n",
      "forma                1\n",
      "7x1                  1\n",
      "kapo                 1\n",
      "cozinha              1\n",
      "nego                 1\n",
      "tentar               1\n",
      "@pedrxcarvalho       1\n",
      "@namgukoo            1\n",
      "suja                 1\n",
      "vitoria              1\n",
      "protege              1\n",
      "estabelecimento      1\n",
      "combinamos           1\n",
      "vinho                1\n",
      "moska                1\n",
      "raiz                 1\n",
      "legal                1\n",
      "tomado               1\n",
      "50                   1\n",
      "barraco              1\n",
      "@agustdvv            1\n",
      "ifood                1\n",
      "eternet              1\n",
      "trof√©u               1\n",
      "porra                1\n",
      "todos                1\n",
      "parab√©ns             1\n",
      "Length: 1354, dtype: int64\n",
      "guaran√°             113\n",
      "de                   92\n",
      "e                    68\n",
      "eu                   54\n",
      "um                   43\n",
      "que                  34\n",
      "√©                    26\n",
      "a                    25\n",
      "o                    23\n",
      "com                  22\n",
      "q                    20\n",
      "n√£o                  20\n",
      "da                   19\n",
      "tomar                16\n",
      "meu                  15\n",
      "pra                  15\n",
      "melhor               14\n",
      "guarana              14\n",
      "mais                 14\n",
      "uma                  14\n",
      "agora                12\n",
      "https                12\n",
      "queria               12\n",
      "to                   12\n",
      "mas                  12\n",
      "//t                  12\n",
      "em                   11\n",
      "rt                   11\n",
      "me                   11\n",
      "do                   10\n",
      "                   ... \n",
      "eh                    1\n",
      "louca                 1\n",
      "pessoa                1\n",
      "ü§©                     1\n",
      "shot                  1\n",
      "piercing              1\n",
      "@lukasssid            1\n",
      "ano                   1\n",
      "ningu√©m               1\n",
      "rj                    1\n",
      "absurdo               1\n",
      "juntos                1\n",
      "manda                 1\n",
      "goles                 1\n",
      "sabor                 1\n",
      "√∫nica                 1\n",
      "@brvmxs               1\n",
      "concentrado           1\n",
      "@emilly_uai           1\n",
      "foda                  1\n",
      "comi                  1\n",
      "anivers√°rio           1\n",
      "bag                   1\n",
      "arriscado             1\n",
      "aprender              1\n",
      "@piiece_of_peace      1\n",
      "dps                   1\n",
      "ga√∫cho                1\n",
      "seu                   1\n",
      "so                    1\n",
      "Length: 740, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#quantas vezes aparecem cada palavra\n",
    "freq_irrel= serie_irrel.value_counts()\n",
    "print(freq_irrel)\n",
    "freq_rel= serie_rel.value_counts()\n",
    "print(freq_rel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Series.sum of guaran√°            0.041657\n",
      "e                  0.029208\n",
      "de                 0.028729\n",
      "eu                 0.020828\n",
      "√©                  0.018674\n",
      "que                0.017237\n",
      "a                  0.016280\n",
      "o                  0.015322\n",
      "com                0.012689\n",
      "um                 0.012689\n",
      "do                 0.010534\n",
      "em                 0.009337\n",
      "//t                0.009097\n",
      "https              0.009097\n",
      "pra                0.009097\n",
      "uma                0.007900\n",
      "n√£o                0.007182\n",
      "rt                 0.006464\n",
      "da                 0.005985\n",
      "q                  0.005985\n",
      "meu                0.005746\n",
      "na                 0.005506\n",
      "l√°                 0.005267\n",
      "se                 0.005028\n",
      "mas                0.004788\n",
      "ou                 0.004549\n",
      "no                 0.004309\n",
      "voc√™               0.004309\n",
      "j√°                 0.004070\n",
      "@guarana           0.004070\n",
      "                     ...   \n",
      "estar              0.000239\n",
      "caracu             0.000239\n",
      "ganha              0.000239\n",
      "forma              0.000239\n",
      "7x1                0.000239\n",
      "kapo               0.000239\n",
      "cozinha            0.000239\n",
      "nego               0.000239\n",
      "tentar             0.000239\n",
      "@pedrxcarvalho     0.000239\n",
      "@namgukoo          0.000239\n",
      "suja               0.000239\n",
      "vitoria            0.000239\n",
      "protege            0.000239\n",
      "estabelecimento    0.000239\n",
      "combinamos         0.000239\n",
      "vinho              0.000239\n",
      "moska              0.000239\n",
      "raiz               0.000239\n",
      "legal              0.000239\n",
      "tomado             0.000239\n",
      "50                 0.000239\n",
      "barraco            0.000239\n",
      "@agustdvv          0.000239\n",
      "ifood              0.000239\n",
      "eternet            0.000239\n",
      "trof√©u             0.000239\n",
      "porra              0.000239\n",
      "todos              0.000239\n",
      "parab√©ns           0.000239\n",
      "Length: 1354, dtype: float64>\n",
      "<bound method Series.sum of guaran√°             0.058885\n",
      "de                  0.047942\n",
      "e                   0.035435\n",
      "eu                  0.028140\n",
      "um                  0.022408\n",
      "que                 0.017718\n",
      "√©                   0.013549\n",
      "a                   0.013028\n",
      "o                   0.011985\n",
      "com                 0.011464\n",
      "q                   0.010422\n",
      "n√£o                 0.010422\n",
      "da                  0.009901\n",
      "tomar               0.008338\n",
      "meu                 0.007817\n",
      "pra                 0.007817\n",
      "melhor              0.007295\n",
      "guarana             0.007295\n",
      "mais                0.007295\n",
      "uma                 0.007295\n",
      "agora               0.006253\n",
      "https               0.006253\n",
      "queria              0.006253\n",
      "to                  0.006253\n",
      "mas                 0.006253\n",
      "//t                 0.006253\n",
      "em                  0.005732\n",
      "rt                  0.005732\n",
      "me                  0.005732\n",
      "do                  0.005211\n",
      "                      ...   \n",
      "eh                  0.000521\n",
      "louca               0.000521\n",
      "pessoa              0.000521\n",
      "ü§©                   0.000521\n",
      "shot                0.000521\n",
      "piercing            0.000521\n",
      "@lukasssid          0.000521\n",
      "ano                 0.000521\n",
      "ningu√©m             0.000521\n",
      "rj                  0.000521\n",
      "absurdo             0.000521\n",
      "juntos              0.000521\n",
      "manda               0.000521\n",
      "goles               0.000521\n",
      "sabor               0.000521\n",
      "√∫nica               0.000521\n",
      "@brvmxs             0.000521\n",
      "concentrado         0.000521\n",
      "@emilly_uai         0.000521\n",
      "foda                0.000521\n",
      "comi                0.000521\n",
      "anivers√°rio         0.000521\n",
      "bag                 0.000521\n",
      "arriscado           0.000521\n",
      "aprender            0.000521\n",
      "@piiece_of_peace    0.000521\n",
      "dps                 0.000521\n",
      "ga√∫cho              0.000521\n",
      "seu                 0.000521\n",
      "so                  0.000521\n",
      "Length: 740, dtype: float64>\n"
     ]
    }
   ],
   "source": [
    "somaR= tabela_relativai.sum()\n",
    "print(somaR)\n",
    "somaI= tabela_relativar.sum()\n",
    "print(somaI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                   @waagfreeitas kkkkk guaran√° do jovem\n",
      "1      @joaomiguelbdb bicho eu penso isso mas com rel...\n",
      "2      a belle pediu p mo√ßa da padaria guarda o guara...\n",
      "3       Ï°∞ÏäπÏó∞ posta foto que eu te dou churrasco e guarana\n",
      "4      @calebesouzao @pedrotolhos @guarana por nada, ...\n",
      "5      @guarana @canellamatheus  @lucasinutilismo  co...\n",
      "6      minha pressao ta caindo mais que a paulinha do...\n",
      "7      @giupanaro @ehdaora vc nao ta mto longe disso,...\n",
      "8      rt @tiobooboodepre: ja teve quarto branco. con...\n",
      "9      deusa aben√ßoe o guaran√° gelado com uma rodela ...\n",
      "10     acabei de colocar guaran√°, caf√©, energ√©tico e ...\n",
      "11     rt @kmeirelles21: ela pensou que era festa e e...\n",
      "12     o que vale mais um guaran√° fruki ou a minha vida?\n",
      "13     @emy_wiki n√£o √© refrigerante, √© tipo um refres...\n",
      "14     @victor_guarana @ehdaora kkkkkkkk tipo de piad...\n",
      "15                      bom dia algu√©m me d√° eno guaran√°\n",
      "16     o auge eu e a minha irm√£ pegando as guaran√° pr...\n",
      "17     @_gabrielos s√≥ me chamar pro churras e me dar ...\n",
      "18     dormi s√≥ 4h essa noite... s√≥ esse meio litro d...\n",
      "19     guaran√° coroa melhor guaran√° quem discorda √© c...\n",
      "20     meu sonho de princesa √© levar o boy pra experi...\n",
      "21                         refri de guarana √© bom demais\n",
      "22     [9/3 22:36] maninha: encomendei 1200 salgados ...\n",
      "23     como que eu vou parar de tomar refri se guaran...\n",
      "24     rt @chelseadepre: hoje vai ter uma festa\\n\\nbo...\n",
      "25     minha folga vou rodar aquele centro atr√°s de p...\n",
      "26     √© o meu anivers√°rio bolo guarana muito doce pr...\n",
      "27     @ellenbarcelloss opaaaaaaa, ent√£o fechou, leva...\n",
      "28     meu pai mandou 4 garrafas de guaran√° jesus, co...\n",
      "29     hoje do nda me deu uma vontade s√∫bita de guara...\n",
      "                             ...                        \n",
      "119    tomo guaran√°! suco de caju! goiabada para sobr...\n",
      "120    cara, eu realmente espero n√£o estar confundind...\n",
      "121    @2xminilyce aa guaran√° n√£o √© mt bom, mas caso ...\n",
      "122                    macarr√£o + guaran√° = tudo pra mim\n",
      "123    gnt o angelo n se valoriza tava ligando pro bo...\n",
      "124    @isa_barbosas15 s√©rio??? ah, o guaran√° tbm n f...\n",
      "125    @aidenj0estar tipo minha tia que chama at√© √°gu...\n",
      "126    t√° certo que eu prefiro guaran√° mas eu to bebe...\n",
      "127    @ana_coment @stitchesns @luagess @thelminha_as...\n",
      "128              @hastadlol e a bebida, vai ser guaran√°?\n",
      "129    @icaroanalises nescau \\nguaran√° \\nj√° fui mais ...\n",
      "130    eu acho que zlatan ibrahimoviƒá foi a √∫nica pes...\n",
      "131    \"existem pessoas que amam guaran√° eu por exemp...\n",
      "132    @moreiranatalia_ falei pra xande a vontade que...\n",
      "133    amanh√£ vou gastar todo meu dinheiro com drogas...\n",
      "134    projeto #bemestar a vencetex apoia! #equipe #g...\n",
      "135    @quiel027 @obqdc me falta o capital kkkkkkkkkk...\n",
      "136    ypi√≥ca guaran√° patrocina essa galera pra mais ...\n",
      "137           eu topo dividir um guarana na pra√ßa brasil\n",
      "138    amanh√£ vou trabalhar s√≥ o pito. vou botar p√≥ d...\n",
      "139    at√© agora sem acreditar que no rio eles ado√ßam...\n",
      "140    esse guaran√° quente deve da uma sede... https:...\n",
      "141           @starkov_alina sigo com meu bolo e guaran√°\n",
      "142    eu sei q todo mundo acha mas ningu√©m tem corag...\n",
      "143    @mavivalenza guaran√° em p√≥, √© bom, mas se vc t...\n",
      "144    nois bebe eh guaran√° nois bebe eh guaran√° cach...\n",
      "145    meu sonho de princesa √© levar o boy pra experi...\n",
      "146    @marcosquezado1 opa! program√£o, ein?! vou acom...\n",
      "147    rt @crvgdanni: p√≥ de guaran√° e amendoim, hoje ...\n",
      "148    rt @mhventura77: @myynfreiitas voltava do cair...\n",
      "Name: Teste, Length: 149, dtype: object\n"
     ]
    }
   ],
   "source": [
    "teste = []\n",
    "tweetsteste= pd.read_excel('guarana.xlsx',sheet_name='Teste')\n",
    "df = pd.DataFrame(tweetsteste)\n",
    "tweets_teste= tweetsteste['Teste']\n",
    "tweets_teste=tweets_teste.drop(columns=\"Teste\")\n",
    "    \n",
    "print(tweets_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laura\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                          @waagfreeitas kkkkk guaran√° do jovem\n",
       "1                             @joaomiguelbdb bicho eu penso isso mas com rel...\n",
       "2                             a belle pediu p mo√ßa da padaria guarda o guara...\n",
       "3                              Ï°∞ÏäπÏó∞ posta foto que eu te dou churrasco e guarana\n",
       "4                             @calebesouzao @pedrotolhos @guarana por nada, ...\n",
       "5                             @guarana @canellamatheus  @lucasinutilismo  co...\n",
       "6                             minha pressao ta caindo mais que a paulinha do...\n",
       "7                             @giupanaro @ehdaora vc nao ta mto longe disso,...\n",
       "8                             rt @tiobooboodepre: ja teve quarto branco. con...\n",
       "9                             deusa aben√ßoe o guaran√° gelado com uma rodela ...\n",
       "10                            acabei de colocar guaran√°, caf√©, energ√©tico e ...\n",
       "11                            rt @kmeirelles21: ela pensou que era festa e e...\n",
       "12                            o que vale mais um guaran√° fruki ou a minha vida?\n",
       "13                            @emy_wiki n√£o √© refrigerante, √© tipo um refres...\n",
       "14                            @victor_guarana @ehdaora kkkkkkkk tipo de piad...\n",
       "15                                             bom dia algu√©m me d√° eno guaran√°\n",
       "16                            o auge eu e a minha irm√£ pegando as guaran√° pr...\n",
       "17                            @_gabrielos s√≥ me chamar pro churras e me dar ...\n",
       "18                            dormi s√≥ 4h essa noite... s√≥ esse meio litro d...\n",
       "19                            guaran√° coroa melhor guaran√° quem discorda √© c...\n",
       "20                            meu sonho de princesa √© levar o boy pra experi...\n",
       "21                                                refri de guarana √© bom demais\n",
       "22                            [9/3 22:36] maninha: encomendei 1200 salgados ...\n",
       "23                            como que eu vou parar de tomar refri se guaran...\n",
       "24                            rt @chelseadepre: hoje vai ter uma festa\\n\\nbo...\n",
       "25                            minha folga vou rodar aquele centro atr√°s de p...\n",
       "26                            √© o meu anivers√°rio bolo guarana muito doce pr...\n",
       "27                            @ellenbarcelloss opaaaaaaa, ent√£o fechou, leva...\n",
       "28                            meu pai mandou 4 garrafas de guaran√° jesus, co...\n",
       "29                            hoje do nda me deu uma vontade s√∫bita de guara...\n",
       "                                                    ...                        \n",
       "122                                           macarr√£o + guaran√° = tudo pra mim\n",
       "123                           gnt o angelo n se valoriza tava ligando pro bo...\n",
       "124                           @isa_barbosas15 s√©rio??? ah, o guaran√° tbm n f...\n",
       "125                           @aidenj0estar tipo minha tia que chama at√© √°gu...\n",
       "126                           t√° certo que eu prefiro guaran√° mas eu to bebe...\n",
       "127                           @ana_coment @stitchesns @luagess @thelminha_as...\n",
       "128                                     @hastadlol e a bebida, vai ser guaran√°?\n",
       "129                           @icaroanalises nescau \\nguaran√° \\nj√° fui mais ...\n",
       "130                           eu acho que zlatan ibrahimoviƒá foi a √∫nica pes...\n",
       "131                           \"existem pessoas que amam guaran√° eu por exemp...\n",
       "132                           @moreiranatalia_ falei pra xande a vontade que...\n",
       "133                           amanh√£ vou gastar todo meu dinheiro com drogas...\n",
       "134                           projeto #bemestar a vencetex apoia! #equipe #g...\n",
       "135                           @quiel027 @obqdc me falta o capital kkkkkkkkkk...\n",
       "136                           ypi√≥ca guaran√° patrocina essa galera pra mais ...\n",
       "137                                  eu topo dividir um guarana na pra√ßa brasil\n",
       "138                           amanh√£ vou trabalhar s√≥ o pito. vou botar p√≥ d...\n",
       "139                           at√© agora sem acreditar que no rio eles ado√ßam...\n",
       "140                           esse guaran√° quente deve da uma sede... https:...\n",
       "141                                  @starkov_alina sigo com meu bolo e guaran√°\n",
       "142                           eu sei q todo mundo acha mas ningu√©m tem corag...\n",
       "143                           @mavivalenza guaran√° em p√≥, √© bom, mas se vc t...\n",
       "144                           nois bebe eh guaran√° nois bebe eh guaran√° cach...\n",
       "145                           meu sonho de princesa √© levar o boy pra experi...\n",
       "146                           @marcosquezado1 opa! program√£o, ein?! vou acom...\n",
       "147                           rt @crvgdanni: p√≥ de guaran√° e amendoim, hoje ...\n",
       "148                           rt @mhventura77: @myynfreiitas voltava do cair...\n",
       "Probabilidade Irrelev√¢ncia    [8.139443732748862e-20, 5.070026939618346e-69,...\n",
       "Probabilidade Relev√¢ncia      [3.739428423065613e-20, 2.329275005297488e-69,...\n",
       "Classifica√ß√£o                 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...\n",
       "Name: Teste, Length: 152, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_relevancia=[]\n",
    "lista_irrelevancia=[]\n",
    "classificacao=[]\n",
    "d=6096 #n√∫mero total de palavras diferentes em ambas as s√©ries\n",
    "\n",
    "\n",
    "for tweet in tweets_teste:\n",
    "    i=0\n",
    "    k=0\n",
    "    alfa= 1\n",
    "    probTweetI= 1\n",
    "    probTweetR=1\n",
    "    tweet_limpo= limpeza(tweet)\n",
    "    palavras= tweet_limpo.split()\n",
    "    \n",
    "    for palavra in palavras:\n",
    "    #calculando a prob do tweet ser irrelevante\n",
    "        if palavra in serie_irrel:\n",
    "            probTweetI*= (freq_irrel[palavra] +alfa)/(d +somaI)\n",
    "        if palavra not in serie_irrel:\n",
    "            probTweetI*=1/d\n",
    "    #calculando a probabilidade dele ser relevante\n",
    "        if palavra in serie_rel:\n",
    "            probTweetR*= (freq_rel[palavra]+alfa)/(d+ somaR)\n",
    "        if palavra not in serie_rel:\n",
    "            probTweetR*=1/d\n",
    "    \n",
    "    lista_irrelevancia.append(probI*probTweetI)\n",
    "    lista_relevancia.append(probR*probTweetR)\n",
    "\n",
    "    \n",
    "\n",
    "tweets_teste[\"Probabilidade Irrelev√¢ncia\"]= lista_irrelevancia\n",
    "tweets_teste[\"Probabilidade Relev√¢ncia\"]= lista_relevancia\n",
    "for i in range(0,149):\n",
    "    if lista_relevancia[i]<lista_irrelevancia[i]:\n",
    "        classificacao.append(\"2\")\n",
    "    else:\n",
    "        classificacao.append(\"1\")\n",
    "tweets_teste[\"Classifica√ß√£o\"]= classificacao\n",
    "\n",
    "tweets_teste\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "a=probTweetR / probTweetR + probTweetI \n",
    "if a > 0.5:\n",
    "    classificacao.append(\"1\")\n",
    "else:\n",
    "     classificacao.append(\"2\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "for alpha in np.arange(0,1,0.01):\n",
    "    if  probTweetR >  alpha * probTweetR + probTweetI: \n",
    "         classificacao.append(\"1\")\n",
    "    else:\n",
    "         classificacao.append(\"2\")\n",
    "        \n",
    "        \n",
    "    \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-f2fefa6b1655>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtweetsteste\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"irrelevancia\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlista_irrelevancia\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtweetsteste\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"relevante\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlista_relevancia\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtweetsteste\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"classificacao_comp\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mclassificacao\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtweetsteste\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3368\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3369\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3370\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3372\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3444\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3445\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3446\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3629\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3630\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3631\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3632\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[1;34m(data, index, copy)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Length of values does not match length of index'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "tweetsteste[\"irrelevancia\"]= lista_irrelevancia\n",
    "tweetsteste[\"relevante\"]= lista_relevancia\n",
    "tweetsteste[\"classificacao_comp\"]= classificacao\n",
    "\n",
    "tweetsteste.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'classificacao_comp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'classificacao_comp'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-fa1151fa73b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mlista_class_comp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtweetsteste\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"classificacao_comp\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'classificacao_comp'"
     ]
    }
   ],
   "source": [
    "#verificando a performance\n",
    "\n",
    "lista_class = tweetsteste [\"classificacao\"].tolist()\n",
    "\n",
    "\n",
    "lista_class_comp=tweetsteste [\"classificacao_comp\"].tolist()\n",
    "\n",
    "\n",
    "\n",
    "i=0\n",
    "s=0\n",
    "while i < 149:\n",
    "    if int(lista_class[i])==int(lista_class_comp[i]):\n",
    "        s+=1\n",
    "    i+=1\n",
    "print(s)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "porcentagem_corretos= s/149\n",
    "print(porcentagem_corretos*100)\n",
    "\n",
    "\n",
    "    \n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
